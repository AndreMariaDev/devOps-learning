# Conhecendo o Kubernetes

## ‚ú® Contexto inicial e problema

### Cen√°rio

- `"Temos Uma aplica√ß√£o executando em container e essa execu√ß√£o em container traz algumas preocupa√ß√µes (Problemas)."`
- `"Temos v√°rias aplica√ß√µes executando em container e essa execu√ß√£o em container traz algumas preocupa√ß√µes (Problemas)."`

### Problemas

- `"E se um container falhar na execu√ß√£o?"`
- `"E se precisarmos de v√°rios containers executando a mesma aplica√ß√£o?"`
- `"E se precisarmos de um fluxo el√°stico?"`
- `"E se forem v√°rias aplica√ß√µes com v√°rios containers?"`
- `"E o controle de uso de recursos de container?"`

## ‚ú® Esbo√ßo do problema

No cen√°rio temos uma aplica√ß√£o `"A"`, a aplica√ß√£o `"A"` est√° contida em um container.

![](image/Kubernetes/app-a-container-a.png)

Quando o container a √© executado, ele necessita de recursos computacionais

![](image/Kubernetes/app-a-container-a-computational-resources.png)

Caso ocorra algum problema no container ,o mesmo vai parar a execu√ß√£o e logo n√£o existe mais.

Quando n√£o trabalhamos com orquestra√ß√£o √© muito dif√≠cil entender os motivos da causa do problema.

Quando n√£o trabalhamos com orquestra√ß√£o n√£o temos a visibilidade de quando um determinado problema ir√° ocorrer.

Caso ocorra o problema como ser√° resolvido?

Sem a orquestra√ß√£o a solu√ß√£o desses problemas √© muito complexa!

Logo √© muito importante que esse cen√°rio seja automatizado.

O kubernetes entra no sen√°rio para resolver esses problemas.

#### **`Conceitos B√°sicos do Kubernetes`**

**`Arquitetura`**

- `"Cluster"`: Conjunto de m√°quinas (n√≥s) que executam aplica√ß√µes em cont√™ineres. Um cluster √© composto por um `Master Node` e v√°rios `Worker Nodes`.
- `"Node"`: Uma √∫nica m√°quina em execu√ß√£o em um cluster Kubernetes, pode ser f√≠sica ou virtual.
- `"Pod"`: Unidade b√°sica de execu√ß√£o em Kubernetes. Um `Pod` pode conter um ou mais cont√™ineres que compartilham recursos de rede e armazenamento.


**`Objetos Principais`**

- `"Pod"`: O menor objeto implant√°vel no Kubernetes. Ele encapsula um ou mais cont√™ineres, com armazenamento compartilhado e configura√ß√µes de rede.
- `"Deployment"`: Gerencia a cria√ß√£o e atualiza√ß√£o de `Pods`. Facilita o controle de vers√µes e rollback.
- `"Service"`: Define uma maneira de expor uma aplica√ß√£o em execu√ß√£o como um servi√ßo de rede.
- `"ConfigMap"`: Armazena dados de configura√ß√£o em pares chave-valor que podem ser consumidos por cont√™ineres.
- `"Secret"`: Semelhante ao `ConfigMap`, mas usado para armazenar dados sens√≠veis, como senhas e chaves de API.


![](image/Kubernetes/app-a-container-a-computational-resources-sh.png)

**`"Self-Healing no Kubernetes"`**

O **self-healing** no Kubernetes √© um recurso que permite ao cluster detectar e corrigir automaticamente falhas em seus componentes, garantindo maior disponibilidade e resili√™ncia das aplica√ß√µes.

**`"Como funciona"`**
- **Pods com falhas**: Se um Pod falhar (parar de responder ou entrar em estado de erro), o Kubernetes recria ou substitui automaticamente o Pod para restaurar o estado desejado.
- **Nodes indispon√≠veis**: Se um n√≥ (node) falhar, os Pods que estavam nele s√£o redistribu√≠dos para outros n√≥s dispon√≠veis.
- **Checagens de sa√∫de**: Kubernetes utiliza *liveness probes* e *readiness probes* para monitorar continuamente os Pods e determinar se est√£o saud√°veis.

**`"Para que serve"`**
1. **Garantir alta disponibilidade**: Minimiza o tempo de inatividade ao corrigir falhas rapidamente.
2. **Automatizar recupera√ß√£o**: Evita a necessidade de interven√ß√£o manual para problemas comuns.
3. **Melhorar resili√™ncia**: Ajuda a manter o sistema funcionando mesmo em condi√ß√µes adversas.

Este recurso √© essencial para aplica√ß√µes modernas que demandam escalabilidade e alta confiabilidade.

![](image/Kubernetes/app-a-container-a-all.png)

Nesse mecanismo e chamado de hpa (Horizontal Pod Autoscaler)


#### O que √© Horizontal Pod Autoscaler (HPA)?

O **Horizontal Pod Autoscaler (HPA)** √© um recurso do Kubernetes que ajusta automaticamente o n√∫mero de r√©plicas de pods em um deployment, replica set ou stateful set com base na utiliza√ß√£o de m√©tricas observadas (como uso de CPU, mem√≥ria ou m√©tricas personalizadas). 

#### Para que serve?

O HPA √© usado para:

- **Escalabilidade autom√°tica**: Garante que o n√∫mero de pods atenda √† demanda vari√°vel do aplicativo.
- **Efici√™ncia de recursos**: Ajuda a evitar subutiliza√ß√£o ou sobrecarga de recursos.
- **Alto desempenho**: Mant√©m o desempenho do aplicativo em momentos de picos de uso.
- **Otimiza√ß√£o de custos**: Ajusta a quantidade de recursos usados para evitar desperd√≠cio.

#### Como funciona?

1. Monitora m√©tricas definidas, como uso de CPU/mem√≥ria ou m√©tricas personalizadas atrav√©s do API Metrics Server.
2. Calcula o n√∫mero ideal de r√©plicas com base nas metas configuradas.
3. Escala automaticamente o n√∫mero de pods para atingir as metas.

Exemplo de uso comum:
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-a
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app-a
  minReplicas: 3
  maxReplicas: 8
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
```

## ‚ú® Principais componentes

#### Arquitetura do Kubernetes

![](image/Kubernetes/arq-kubernetes.png)

- **Control Plane**:
O **Control Plane** gerencia o estado desejado do cluster, monitorando e controlando os componentes do Kubernetes. Ele coordena os n√≥s, agendando workloads e respondendo a eventos do sistema.

---

- **API Server**:
O **API Server** √© o ponto de entrada para todas as intera√ß√µes externas e internas com o Kubernetes. Ele exp√µe a API RESTful do Kubernetes e √© respons√°vel por autenticar e validar as solicita√ß√µes.

---

- **Cloud Controller Manager**:
O **Cloud Controller Manager** integra o Kubernetes ao provedor de nuvem. Ele gerencia recursos dependentes da infraestrutura da nuvem, como balanceadores de carga, volumes de armazenamento e n√≥s virtuais.

---

- **ETCD (Persistence Store)**:
O **ETCD** √© o armazenamento de dados distribu√≠do usado pelo Kubernetes para salvar todos os dados do cluster. Ele √© a √∫nica fonte de verdade, contendo configura√ß√µes, estados de objetos e informa√ß√µes cr√≠ticas.

---

- **Kubelet**:
O **Kubelet** √© o agente que roda em cada n√≥ do cluster. Ele recebe instru√ß√µes do API Server e garante que os containers estejam rodando como especificado nos objetos Pod.

---

- **Kube-proxy**:
O **Kube-proxy** gerencia as regras de rede dentro do cluster, garantindo a comunica√ß√£o entre Pods e servi√ßos, al√©m de lidar com o balanceamento de carga interno.

---

- **Scheduler**:
O **Scheduler** decide em qual n√≥ os Pods rec√©m-criados devem ser executados, baseando-se em fatores como recursos dispon√≠veis, restri√ß√µes de afinidade e anti-afinidade.

---

- **Node**:
O **Node** √© uma m√°quina (f√≠sica ou virtual) que executa os workloads do Kubernetes. Cada n√≥ cont√©m um **Kubelet**, um **Kube-proxy** e o ambiente necess√°rio para rodar containers.


## ‚ú® Como executar um Cluster Kubernetes

Tipos de cluster

- Gerenciado : Pago [AWS-EKS, GCP-GKE, AZURE-AKS]
- N√£o Gerenciado : OnPremise, (na sua m√°quina)

## ‚ú® Configurando Ambiente

Ferramentas:

- Kubectl: CLI 
- lens (IDE)
- K9s 
- (na sua m√°quina) : Kind(`"Kubernetes in docker"`), Minikube, K3d/k3s

https://kubernetes.io/pt-br/docs/tasks/tools/

https://docs.k8slens.dev/

## ‚ú® Configurando e criando nosso primeiro Cluster

- Vamos criar uma cluster, para isso vamos digitar o seguinte comando no terminal:

```
kind create cluster --name=first-cluster-rocketseat
```

Logo apos no terminal e apresentado o resukltado da cria√ß√£o:
```hcl

ster --name=first-cluster-rocketseat
Creating cluster "first-cluster-rocketseat" ...
 ‚Ä¢ Ensuring node image (kindest/node:v1.31.2) üñº  ...
 ‚úì Ensuring node image (kindest/node:v1.31.2) üñº
 ‚Ä¢ Preparing nodes üì¶   ...
 ‚úì Preparing nodes üì¶
 ‚Ä¢ Writing configuration üìú  ...
 ‚úì Writing configuration üìú
 ‚Ä¢ Starting control-plane üïπÔ∏è  ...
 ‚úì Starting control-plane üïπÔ∏è
 ‚Ä¢ Installing CNI üîå  ...
 ‚úì Installing CNI üîå
 ‚Ä¢ Installing StorageClass üíæ  ...
 ‚úì Installing StorageClass üíæ
Set kubectl context to "kind-first-cluster-rocketseat"
You can now use your cluster with:

kubectl cluster-info --context kind-first-cluster-rocketseat

Not sure what to do next? üòÖ  Check out https://kind.sigs.k8s.io/docs/user/quick-start/

```

O result acima indicou a o uso do contexto : ```kubectl cluster-info --context kind-first-cluster-rocketseat```

```hcl

PS C:\Repo\k8s\first-cluster> kubectl cluster-info --context kind-first-cluster-rocketseat
Kubernetes control plane is running at https://127.0.0.1:49448
CoreDNS is running at https://127.0.0.1:49448/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.

```

Agora vamos rtoadr o comando `kubectl` que apresentar√° a lista de coamndo que podemos usar:

```hcl

 kubectl 
kubectl controls the Kubernetes cluster manager.

 Find more information at: https://kubernetes.io/docs/reference/kubectl/

Basic Commands (Beginner):
  create          Create a resource from a file or from stdin
  expose          Take a replication controller, service, deployment or pod and expose it as a new Kubernetes service
  run             Run a particular image on the cluster
  set             Set specific features on objects

Basic Commands (Intermediate):
  explain         Get documentation for a resource
  get             Display one or many resources
  edit            Edit a resource on the server
  delete          Delete resources by file names, stdin, resources and names, or by resources and label selector

Deploy Commands:
  rollout         Manage the rollout of a resource
  scale           Set a new size for a deployment, replica set, or replication controller
  autoscale       Auto-scale a deployment, replica set, stateful set, or replication controller

Cluster Management Commands:
  certificate     Modify certificate resources
  cluster-info    Display cluster information
  top             Display resource (CPU/memory) usage
  cordon          Mark node as unschedulable
  uncordon        Mark node as schedulable
  drain           Drain node in preparation for maintenance
  taint           Update the taints on one or more nodes

Troubleshooting and Debugging Commands:
  describe        Show details of a specific resource or group of resources
  logs            Print the logs for a container in a pod
  attach          Attach to a running container
  exec            Execute a command in a container
  port-forward    Forward one or more local ports to a pod
  proxy           Run a proxy to the Kubernetes API server
  cp              Copy files and directories to and from containers
  auth            Inspect authorization
  debug           Create debugging sessions for troubleshooting workloads and nodes
  events          List events

Advanced Commands:
  diff            Diff the live version against a would-be applied version
  apply           Apply a configuration to a resource by file name or stdin
  patch           Update fields of a resource
  replace         Replace a resource by file name or stdin
  wait            Experimental: Wait for a specific condition on one or many resources
  kustomize       Build a kustomization target from a directory or URL

Settings Commands:
  label           Update the labels on a resource
  annotate        Update the annotations on a resource
  completion      Output shell completion code for the specified shell (bash, zsh, fish, or powershell)

Subcommands provided by plugins:

Other Commands:
  api-resources   Print the supported API resources on the server
  api-versions    Print the supported API versions on the server, in the form of "group/version"
  config          Modify kubeconfig files
  plugin          Provides utilities for interacting with plugins
  version         Print the client and server version information

Usage:
  kubectl [flags] [options]

Use "kubectl <command> --help" for more information about a given command.
Use "kubectl options" for a list of global command-line options (applies to all commands).

```

Logo vamos usar o seguinte comando : `kubectl get nodes`


```
PS C:\Repo\k8s\first-cluster> kubectl get nodes
NAME                                     STATUS   ROLES           AGE   VERSION
first-cluster-rocketseat-control-plane   Ready    control-plane   16m   v1.31.2
PS C:\Repo\k8s\first-cluster> 
```

Agora vamos abiri o lens.

![](image/Kubernetes/start-lens.png)


## ‚ú® Configurando Cluster com multiplos n√≥s

Vamos Excluir o primeiro cluster : `kind delete cluster --name=first-cluster-rocketseat`

Agora vamos escrever um script manifesto para a cria√ß√£o de um novo cluster.

- `"kind.yaml"`: vamos criar um novo arquivo para incluir as intru√ß√µes do novo cluster

- `"script base"`: Inclua o seguinte c√≥digo

```hcl

kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
  - role: worker
```

- `"Command"` : No terminal digite o seguinte comando :

`kind create cluster --config kind.yaml --name=secund-cluster-rocketseat` 

![](image/Kubernetes/create-secund-cluster-rocketseat.png)

`kubectl cluster-info --context kind-secund-cluster-rocketseat`

`kubectl get nodes`

![](image/Kubernetes/get-nodes-secund-cluster-rocketseat.png)

#### Explica√ß√£o do Arquivo de Configura√ß√£o Kind

Este √© um arquivo de configura√ß√£o para o Kubernetes in Docker (Kind), utilizado para criar clusters Kubernetes localmente com fins de desenvolvimento e teste.

---

##### **Cabe√ßalho**

```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
```

1. **`kind: Cluster`**
   - Especifica o tipo de recurso que o arquivo define.
   - Indica que o arquivo descreve um *cluster* completo do Kubernetes que ser√° gerenciado pelo Kind.

2. **`apiVersion: kind.x-k8s.io/v1alpha4`**
   - Define a vers√£o da API do Kind utilizada neste arquivo.
   - Esta vers√£o controla as op√ß√µes de configura√ß√£o dispon√≠veis para criar e gerenciar clusters.

---

##### **Configura√ß√£o de N√≥s**

```yaml
nodes:
  - role: control-plane
  - role: worker
```

1. **`nodes`**
   - Define os n√≥s (*nodes*) que far√£o parte do cluster.
   - Cada n√≥ √© uma inst√¢ncia do Kubernetes e pode ser configurado como um n√≥ de controle ou de trabalho.

2. **`- role: control-plane`**
   - Define que o primeiro n√≥ ser√° um **n√≥ de controle** (*control-plane*).
   - O n√≥ de controle √© respons√°vel por executar os componentes principais do Kubernetes, incluindo:
     - **API Server**: Ponto de entrada para comandos e consultas ao cluster.
     - **Controller Manager**: Garante que o estado desejado dos objetos seja mantido.
     - **Scheduler**: Aloca pods em n√≥s dispon√≠veis.
     - **etcd**: Banco de dados chave-valor que armazena todos os dados do cluster.

3. **`- role: worker`**
   - Define que o segundo n√≥ ser√° um **n√≥ de trabalho** (*worker*).
   - Os n√≥s de trabalho executam os **pods**, que cont√™m os cont√™ineres das aplica√ß√µes.
   - Cada n√≥ de trabalho √© gerenciado pelo n√≥ de controle e executa:
     - **kubelet**: Agente que garante que os cont√™ineres dos pods sejam executados como especificado.
     - **kube-proxy**: Mant√©m regras de rede para a comunica√ß√£o interna e externa do cluster.
     - **Container Runtime**: Software que executa os cont√™ineres (ex.: Docker, containerd).

---

##### **Resumo**

Este arquivo cria um cluster Kubernetes com:

- **1 N√≥ de Controle**: Respons√°vel por gerenciar o cluster.
- **1 N√≥ de Trabalho**: Respons√°vel por executar os aplicativos em cont√™iner.

Para criar o cluster utilizando este arquivo, use o comando:

```bash
kind create cluster --config=<nome-do-arquivo.yaml>
```

Esse tipo de configura√ß√£o √© ideal para criar ambientes simples e locais, simulando clusters Kubernetes reais

![](image/Kubernetes/view-docker-creted-cluster.png)




# Orquestrando Containers


## ‚ú® Subindo o nosso primeiro Container

Aqui vamos iniciar a crea√ß√£o de um pod 

Como um Pod √© respons√°vel por (Rodar a nossa aplica√ß√£o dentro do cluster)
Vamos trabalhar nesse ponto.


- `"imagem para o container"` : Vamos acessar o site do dockerhub https://hub.docker.com/_/nginx/tags?name=alpine


- `kubectl run nginx --image=nginx:stable-alpine3.20-perl`

- `kubectl get pods`

- `kubectl describe pod nginx`


![](image/Kubernetes/pod-nginx.png)

- `"Execu√ß√£o de forma IMPERATIVA"` : `kubectl run nginx --image=nginx:stable-alpine3.20-perl`

- `"N√£o temos o controlador"`

## ‚ú® Valor dos manifestos declarativos e namespaces

Vamos deletar o exemplo: ` kubectl delete pod nginx`

Agora vamos criar a namespace : `kubectl create namespace first-app`

Feito isso vamos criar o pod via arquivo. Para isso vamos criar um novo arquivo pod.yaml

#### Explica√ß√£o Detalhada do Script YAML para Cria√ß√£o de um Pod no Kubernetes

Este documento explica cada passo do script YAML fornecido para criar um Pod no Kubernetes.

```yaml
apiVersion: v1
kind: Pod

metadata:
  name: nginx

spec:
  containers:
    - name : nginx
      image: nginx:stable-alpine3.20-perl
      ports:
        - containerPort: 80
      resources:
        requests:
          cpu: 100m
          memory: 64Mi
        limits:
          cpu: 200m
          memory: 128Mi
```

####  1. **Cabe√ßalho do Documento**

#### `apiVersion: v1`
- Define a vers√£o da API do Kubernetes utilizada para este recurso.
- `v1` √© a vers√£o est√°vel para recursos b√°sicos como `Pod`.

#### `kind: Pod`
- Especifica o tipo de recurso que ser√° criado.
- Neste caso, estamos criando um **Pod**, que √© a menor unidade execut√°vel no Kubernetes.

---

#### 2. **Metadados do Pod**

#### `metadata:`
- Define informa√ß√µes adicionais sobre o recurso.

#### `name: nginx`
- Atribui o nome **nginx** ao Pod.
- Este nome deve ser √∫nico dentro do namespace onde o Pod est√° sendo criado.

---

#### 3. **Especifica√ß√µes do Pod**

#### `spec:`
- Cont√©m a descri√ß√£o detalhada de como o Pod ser√° configurado.

#### `containers:`
- Define os containers que ser√£o executados no Pod. Cada Pod pode conter um ou mais containers.

##### `- name: nginx`
- Especifica o nome do container.
- O nome deve ser √∫nico dentro do Pod e √© usado para identificar o container.

##### `image: nginx:stable-alpine3.20-perl`
- Indica a imagem Docker que ser√° usada para criar o container.
- Neste caso, a imagem √© **nginx:stable-alpine3.20-perl**, que √© uma vers√£o leve e est√°vel do servidor web NGINX.

##### `ports:`
- Define as portas expostas pelo container.

###### `- containerPort: 80`
- Especifica que o container expor√° a porta **80**, comumente usada para servi√ßos HTTP.

---

#### 4. **Recursos do Container**

#### `resources:`
- Configura os limites e as solicita√ß√µes de recursos para o container.

#### `requests:`
- Representa a quantidade m√≠nima de recursos garantidos para o container.

##### `cpu: 100m`
- O container requer pelo menos **100 millicores** (0,1 vCPU).

##### `memory: 64Mi`
- O container requer pelo menos **64 MiB** de mem√≥ria.

#### `limits:`
- Representa a quantidade m√°xima de recursos que o container pode usar.

##### `cpu: 200m`
- O container pode usar at√© **200 millicores** (0,2 vCPU).

##### `memory: 128Mi`
- O container pode usar at√© **128 MiB** de mem√≥ria.

---

#### Resumo
Este script YAML configura um Pod com:
- Um container baseado na imagem **nginx:stable-alpine3.20-perl**.
- Exposi√ß√£o da porta 80.
- Garantia de uso m√≠nimo de **0,1 vCPU** e **64 MiB** de mem√≥ria.
- Limite m√°ximo de **0,2 vCPU** e **128 MiB** de mem√≥ria.

O Pod criado √© eficiente para servi√ßos de baixa utiliza√ß√£o, ideal para ambientes leves ou de desenvolvimento.

Agora vamos rodar o cmando :
¬¥kubectl apply -f pod.yaml -n first-app¬¥

#### Comando `kubectl apply -f pod.yaml -n first-app`

Este comando utiliza o `kubectl` para aplicar configura√ß√µes de um arquivo YAML a um cluster Kubernetes. Aqui est√£o os detalhes de cada parte do comando:

#### 1. `kubectl`
- **Defini√ß√£o**: `kubectl` √© a ferramenta de linha de comando utilizada para interagir com o Kubernetes.
- **Fun√ß√£o neste comando**: Serve como a base para executar comandos que gerenciam recursos no cluster Kubernetes.

#### 2. `apply`
- **Defini√ß√£o**: O subcomando `apply` √© usado para aplicar ou atualizar a configura√ß√£o de recursos no cluster.
- **Fun√ß√£o neste comando**: Indica ao Kubernetes que ele deve criar ou atualizar os recursos descritos no arquivo `pod.yaml`.

#### 3. `-f pod.yaml`
- **Defini√ß√£o**:
  - O argumento `-f` (abrevia√ß√£o de `--filename`) especifica o arquivo YAML contendo a defini√ß√£o dos recursos Kubernetes a serem aplicados.
  - `pod.yaml` √© o nome do arquivo que cont√©m a descri√ß√£o dos recursos, como pods, services ou deployments.
- **Fun√ß√£o neste comando**: Fornece ao `kubectl` os detalhes da configura√ß√£o do pod para aplica√ß√£o no cluster.

#### 4. `-n first-app`
- **Defini√ß√£o**:
  - `-n` (abrevia√ß√£o de `--namespace`) especifica o namespace no qual os recursos devem ser criados ou atualizados.
  - `first-app` √© o nome do namespace alvo.
- **Fun√ß√£o neste comando**: Garante que o recurso seja aplicado no namespace correto (neste caso, `first-app`).
  - Se o namespace n√£o for especificado, o Kubernetes utiliza o namespace padr√£o (geralmente chamado `default`).

---

Com isso, o comando `kubectl apply -f pod.yaml -n first-app` permite criar ou atualizar recursos em um namespace Kubernetes de maneira organizada e eficiente.


![](image/Kubernetes/pod-first-app.png)


## ‚ú® Acessando container dentro do cluster

#### Explica√ß√£o do Comando `kubectl port-forward pod/nginx -n first-app 8080:80`

O comando `kubectl port-forward` √© usado no Kubernetes para encaminhar portas de um recurso (como um pod) no cluster para o ambiente local. Isso permite acessar aplicativos executados no cluster sem exp√¥-los publicamente por meio de um servi√ßo ou ingress.

#### Detalhamento do comando:

```bash
kubectl port-forward pod/nginx -n first-app 8080:80
```

#### Componentes do Comando:

1. **`kubectl port-forward`**:
   - Essa √© a funcionalidade do `kubectl` que inicia o encaminhamento de portas.

2. **`pod/nginx`**:
   - Especifica o recurso que ser√° o alvo do encaminhamento de portas.
   - Aqui, estamos nos referindo ao pod chamado `nginx`. O prefixo `pod/` indica explicitamente que o recurso √© um pod.

3. **`-n first-app`**:
   - Especifica o namespace onde o pod est√° localizado.
   - Neste caso, o pod `nginx` pertence ao namespace `first-app`.

4. **`8080:80`**:
   - Define o mapeamento de portas.
   - O primeiro n√∫mero (`8080`) √© a porta na m√°quina local (host), que ser√° usada para acessar o aplicativo.
   - O segundo n√∫mero (`80`) √© a porta no pod, onde o aplicativo est√° escutando.

#### O que acontece ao executar esse comando?

- Uma conex√£o √© estabelecida entre o pod `nginx` no namespace `first-app` e a m√°quina local.
- As solicita√ß√µes enviadas para `localhost:8080` (m√°quina local) ser√£o encaminhadas para a porta `80` no pod `nginx` dentro do cluster Kubernetes.
- N√£o √© necess√°rio expor o servi√ßo ou criar um recurso adicional para acessar o aplicativo.

#### Cen√°rios de Uso

- **Depura√ß√£o**:
  - Verificar se o aplicativo est√° funcionando corretamente no pod.
- **Desenvolvimento Local**:
  - Acessar aplicativos no cluster sem configurar servi√ßos ou ingress.
- **Teste Tempor√°rio**:
  - Testar endpoints ou funcionalidades de um aplicativo diretamente.

#### Observa√ß√µes Importantes

1. **Necessidade de Acesso ao Cluster**:
   - O comando requer que voc√™ tenha permiss√µes para acessar o namespace e o pod especificados.

2. **Conex√£o Limitada ao Tempo de Execu√ß√£o**:
   - O encaminhamento permanece ativo apenas enquanto o comando estiver em execu√ß√£o no terminal.

3. **Desempenho e Escalabilidade**:
   - Este m√©todo √© ideal para uso em casos simples ou tempor√°rios. Para ambientes de produ√ß√£o, √© recomendado usar servi√ßos, ingress ou outras solu√ß√µes mais robustas.

4. **Restri√ß√µes de Portas Locais**:
   - Certifique-se de que a porta local especificada (`8080`) n√£o esteja em uso por outro processo.

---

### Exemplo Pr√°tico

Ap√≥s executar o comando:

```bash
kubectl port-forward pod/nginx -n first-app 8080:80
```

Voc√™ pode acessar o aplicativo executado no pod `nginx` digitando o seguinte no navegador ou usando ferramentas como `curl`:

```bash
http://localhost:8080
```

Isso redirecionar√° as solicita√ß√µes para o pod `nginx` na porta `80` dentro do namespace `first-app` do cluster Kubernetes.



## ‚ú® Problemas e pr√≥ximos passos

#### O Que Acontece ao deleta o `Pod` criados?

Ao deletar o Pod:

1. **`"Recria√ß√£o Autom√°tica"`**: N√£o ocorrer√° recria√ß√£o autom√°tica porque o Pod foi criado diretamente sem estar associado a um controlador.
2. **`"Perda Permanente"`**: Uma vez deletado, o Pod e qualquer dado nele contido (se n√£o houver volumes persistentes configurados) ser√£o permanentemente removidos.

Usar um `"ReplicaSet"` poderia ser uma solu√ß√£o paliativa para garantir a recria√ß√£o autom√°tica de um Pod caso ele seja exclu√≠do. 

#### O Que Acontece ao Deletar os Pods Criados por um ReplicaSet?

Se voc√™ deletar os pods criados por um **ReplicaSet** no Kubernetes, o ReplicaSet automaticamente recriar√° os pods para garantir que o n√∫mero especificado em `spec.replicas` seja mantido. 

Esse comportamento faz parte do objetivo do ReplicaSet de assegurar que o estado desejado do sistema seja preservado.

---

#### Explica√ß√£o Detalhada

#### 1. **ReplicaSet Monitora o Estado**
O ReplicaSet verifica constantemente o n√∫mero de pods em execu√ß√£o, baseando-se no `selector.matchLabels`. 

- Quando detecta que h√° menos pods do que o especificado em `spec.replicas`, ele cria novos pods para restaurar o estado desejado.

---

#### 2. **A√ß√£o Ap√≥s a Dele√ß√£o**
- Ao deletar um pod gerenciado pelo ReplicaSet, ele detecta a aus√™ncia desse pod e recria um novo imediatamente.
- O novo pod ser√° baseado no modelo definido na se√ß√£o `template` do ReplicaSet.

---

#### 3. **Imutabilidade dos Pods**
- Os pods criados pelo ReplicaSet s√£o independentes e imut√°veis. Alterar diretamente um pod (como modificar sua configura√ß√£o) n√£o afeta o modelo do ReplicaSet.
- Se um pod for modificado manualmente, o ReplicaSet substituir√° esse pod por outro que siga o modelo original.

---

#### 4. **Impacto no Cluster**
- Caso todos os pods gerenciados sejam deletados, o ReplicaSet recriar√° os pods at√© atingir o n√∫mero especificado em `replicas`.
- Se os recursos do cluster (CPU, mem√≥ria, etc.) forem insuficientes, o ReplicaSet continuar√° tentando recriar os pods at√© que os recursos estejam dispon√≠veis.

---

#### Exce√ß√£o: Dele√ß√£o do Pr√≥prio ReplicaSet
- Se o **ReplicaSet** for deletado, todos os pods gerenciados por ele tamb√©m ser√£o removidos, j√° que dependem do ReplicaSet para existir.

---

#### Caso Pr√°tico
Voc√™ pode testar a recria√ß√£o autom√°tica dos pods com os seguintes comandos:

1. **Deletar um Pod**:
   ```bash
   kubectl delete pod <nome-do-pod>
   ```


2. **Verificar os Pods Dispon√≠veis**:
    ```bash
    kubectl get pods
    ```
    Ap√≥s a execu√ß√£o, voc√™ ver√° que um novo pod foi recriado automaticamente, com um nome diferente, mas baseado no modelo definido no ReplicaSet.

#### Resumo

  - Manuten√ß√£o do n√∫mero de r√©plicas: O ReplicaSet garante que o n√∫mero de r√©plicas definido seja sempre mantido.

  - Recria√ß√£o autom√°tica: Pods deletados ser√£o recriados automaticamente.

  - Imutabilidade: Alterar pods diretamente n√£o afeta o modelo do ReplicaSet; eles ser√£o substitu√≠dos.

  - Dele√ß√£o do ReplicaSet: Se o ReplicaSet for deletado, os pods associados tamb√©m ser√£o removidos.

  Este comportamento torna o ReplicaSet uma ferramenta poderosa para manter a alta disponibilidade de aplicativos no Kubernetes.

## ‚ú® Criando um ReplicaSet

#### Usando o ReplicaSet
```yaml
apiVersion: apps/v1
kind: ReplicaSet

metadata:
  name: nginx

spec:
  replicas: 5
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec: 
      containers:
        - name : nginx
          image: nginx:stable-alpine3.20-perl
          ports:
            - containerPort: 80
          resources:
            requests:
              cpu: 100m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 128Mi
```

#### Explica√ß√£o do Comando ReplicaSet

O comando especificado √© um manifesto em formato YAML usado para criar um **`"ReplicaSet"`** no Kubernetes. 

Um **`"ReplicaSet"`** √© respons√°vel por garantir que um n√∫mero especificado de r√©plicas **`"(pods)"`**  esteja sempre em execu√ß√£o. 

Abaixo est√° a explica√ß√£o detalhada de cada se√ß√£o:

#### Estrutura do Manifesto

#### **`"apiVersion: apps/v1"`** 
Define a vers√£o da API utilizada para o recurso. Nesse caso, o ReplicaSet usa a API `apps/v1`, que √© est√°vel para gerenciar aplicativos no Kubernetes.

---

#### **`"kind: ReplicaSet"`** 
Especifica o tipo de recurso que est√° sendo criado. Aqui, o recurso √© um **ReplicaSet**.

---

#### **`"metadata:"`** 
Cont√©m informa√ß√µes b√°sicas de identifica√ß√£o do objeto.

- **name**: O nome do ReplicaSet. No exemplo, ele √© chamado de `nginx`.

---

#### **`"spec:"`** 
Define a especifica√ß√£o desejada para o ReplicaSet, como o n√∫mero de r√©plicas e a configura√ß√£o dos pods.

#### **`"replicas: 5"`** 
Especifica o n√∫mero desejado de r√©plicas do pod. O ReplicaSet garante que exatamente 5 pods estejam sempre em execu√ß√£o.

#### **`"selector:"`** 
Define como o ReplicaSet identifica os pods que ele deve gerenciar.

- **`matchLabels`**: Especifica os r√≥tulos usados para associar os pods ao ReplicaSet. Neste caso, ele seleciona pods com o r√≥tulo `app: nginx`.

#### **`"template:"`** 
Define o modelo (template) para os pods que o ReplicaSet ir√° criar. Essa se√ß√£o √© usada para configurar os pods.

- **`metadata`**:
  - **`labels`**: Define os r√≥tulos atribu√≠dos aos pods criados. Esses r√≥tulos devem corresponder aos definidos em `selector.matchLabels`.

- **`spec`**: 
  Configura√ß√µes espec√≠ficas dos containers dentro dos pods.

#### **`"containers:"`** 
Lista os containers que devem ser executados no pod.

- **`name`**: Nome do container (no exemplo, `nginx`).
- **`image`**: Imagem do container a ser usada. Aqui, √© especificada a imagem `nginx:stable-alpine3.20-perl`, que √© uma vers√£o leve do NGINX com suporte ao Perl.
- **`ports`**:
  - **`containerPort`**: Define a porta exposta pelo container. No exemplo, o container escuta na porta 80.

#### **`"resources:"`** 
Define as solicita√ß√µes e limites de recursos para o container.

- **`requests`**: Recursos m√≠nimos garantidos para o container.
  - **`cpu`**: `100m` (milicores de CPU) ‚Äî o container receber√° pelo menos 0,1 de um n√∫cleo.
  - **`memory`**: `64Mi` ‚Äî o container ter√° pelo menos 64 MiB de mem√≥ria garantida.

- **`limits`**: Recursos m√°ximos permitidos para o container.
  - **`cpu`**: `200m` (milicores de CPU) ‚Äî o container n√£o pode usar mais do que 0,2 de um n√∫cleo.
  - **`memory`**: `128Mi` ‚Äî o container n√£o pode usar mais do que 128 MiB de mem√≥ria.

---

#### Resumo
Este manifesto cria um **`"ReplicaSet"`** chamado `nginx`, que mant√©m 5 r√©plicas de um pod executando um container NGINX baseado na imagem `nginx:stable-alpine3.20-perl`. 
Os pods s√£o configurados para escutar na porta 80 e possuem restri√ß√µes de CPU e mem√≥ria definidas para otimizar o uso de recursos do cluster.

Agora vamos executar o comando:

```bash
kubectl apply -f replicaset.yaml
```

![](image/Kubernetes/create-replicas.png)

![](image/Kubernetes/replicaset-pods.png)



## ‚ú® Problemas de um ReplicaSet

#### Problemas de Usar o ReplicaSet no Kubernetes

O objeto **`"ReplicaSet"`** no Kubernetes √© respons√°vel por garantir que um n√∫mero especificado de r√©plicas de um pod esteja sempre em execu√ß√£o. No entanto, seu uso direto pode trazer alguns problemas e limita√ß√µes, principalmente quando comparado a outros recursos, como o **`"Deployment**. Abaixo est√£o os principais problemas e implica√ß√µes de usar o ReplicaSet no comando fornecido:

1. **`"Falta de Gerenciamento de Atualiza√ß√µes**
O **`"ReplicaSet"`"`** n√£o fornece uma maneira nativa de gerenciar atualiza√ß√µes ou rollbacks. Isso significa que:

- Para atualizar uma imagem ou qualquer outra configura√ß√£o, o ReplicaSet existente precisa ser deletado ou modificado manualmente, o que pode causar interrup√ß√µes.
- Rollbacks em caso de falhas n√£o s√£o autom√°ticos. Se algo der errado, √© necess√°rio reverter manualmente a configura√ß√£o para um estado anterior.

Em contrapartida, o **`"Deployment"`** abstrai o ReplicaSet e oferece suporte nativo para atualiza√ß√µes declarativas e seguras.

2. **`"Complexidade no Escalonamento Manual"`** 
Embora o ReplicaSet permita o escalonamento ajustando o campo `replicas`, o processo √© manual e sujeito a erros. Ferramentas de escalonamento autom√°tico (Horizontal Pod Autoscaler) geralmente s√£o configuradas em conjunto com um Deployment e n√£o diretamente com um ReplicaSet.

3. **`"Gest√£o Limitada de Ciclo de Vida"`** 
O ReplicaSet n√£o controla o ciclo de vida completo de um aplicativo. Ele apenas mant√©m a quantidade de r√©plicas definida, mas n√£o gerencia estados intermedi√°rios, como:

- Estrat√©gias de atualiza√ß√£o (por exemplo, `RollingUpdate` ou `Recreate`).
- Orquestra√ß√£o em cen√°rios de alta complexidade (como blue/green deployments ou canary deployments).

4. **`"Aumento do Risco de Configura√ß√µes Incorretas"`** 
Sem a abstra√ß√£o e automa√ß√£o fornecidas por um Deployment:

- Configura√ß√µes podem ser aplicadas de maneira inconsistente.
- Existe um risco maior de deletar ou alterar acidentalmente o ReplicaSet em produ√ß√£o, causando interrup√ß√µes.

5. **`"Menor Ado√ß√£o e Suporte"`** 
Na pr√°tica, o uso direto de ReplicaSets √© raro, pois o Deployment √© amplamente adotado devido √† sua flexibilidade e recursos adicionais. Isso pode resultar em:

- Menor suporte de comunidades e ferramentas de terceiros.
- Dificuldades para integrar configura√ß√µes de CI/CD e pr√°ticas modernas de DevOps diretamente com ReplicaSets.

6. **`"Observabilidade Reduzida"`** 
Enquanto um Deployment oferece melhores m√©tricas e status para acompanhar o progresso de atualiza√ß√µes e escalonamento, o ReplicaSet n√£o oferece esses n√≠veis de observabilidade de maneira integrada.

#### Considera√ß√µes Finais
Embora o ReplicaSet seja a base para recursos como o Deployment, seu uso direto √© recomendado apenas para casos muito espec√≠ficos, como:

- Cen√°rios onde n√£o √© necess√°rio realizar atualiza√ß√µes no aplicativo.
- Configura√ß√µes extremamente simples e est√°veis que n√£o exigem a abstra√ß√£o e automa√ß√£o oferecidas por um Deployment.

Na maioria dos casos, √© mais adequado usar um **`"Deployment"`** , que oferece um gerenciamento mais robusto, eficiente e seguro para aplica√ß√µes no Kubernetes.

**`"LOGO O REPLICASET N√ÉO √â UM OBJETOS DE IMPLANTA√á√ÉO MAS SIM UMA CONTROLADOR DE N√öMERO DE PODS. ELE N√ÉO TEM SUPORTE A TROCA DE TAGS."`**

## ‚ú® Criando um Deployment

Agora para resolver o problema visto no uso do **`"ReplicaSet"`** vamos criar um novo arquivo `deployment.yaml`

Ap√≥s a cria√ß√£o do arquivo vamos preencher com o seguinte script:

```yaml

apiVersion: apps/v1
kind: Deployment

metadata:
  name: nginx

spec:
  replicas: 5
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:stable-alpine3.20-perl
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            memory: "128Mi"
            cpu: "200m"
        ports:
        - containerPort: 80


```

```bash
kubectl apply -f deployment.yaml -n first-app
```

![](image/Kubernetes/overview-deployment-pods.png)

Vimos que a vers√£o da imagem √© `nginx:stable-alpine3.20-perl`
![](image/Kubernetes/overview-deployment-pod-version.png)


Para testar o ideia de troca de vers√£o vamos editar o arquivo `deployment.yaml` substituindo `nginx:stable-alpine3.20-perl` para `nginx:mainline-alpine3.20-slim`

```yaml

apiVersion: apps/v1
kind: Deployment

metadata:
  name: nginx

spec:
  replicas: 5
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:mainline-alpine3.20-slim
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            memory: "128Mi"
            cpu: "200m"
        ports:
        - containerPort: 80


```

![](image/Kubernetes/overview-deployment-pod-version-change.png)


## ‚ú® Acessando Pods

Componente da interface de rede onde os acessos pelo Client √© distribuido entre os pods.

Agora para resolver o problema de acesso vamos criar um novo arquivo `service.yaml`

Ap√≥s a cria√ß√£o do arquivo vamos preencher com o seguinte script:

```yaml

apiVersion: v1
kind: Service
metadata:
  name: nginx-svc
spec:
  type: ClusterIP
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 80 # - containerPort: 80 deployment.yaml


```

### Explica√ß√£o Detalhada do Script YAML

O script abaixo descreve um recurso `Service` no Kubernetes, que atua como uma abstra√ß√£o para expor aplica√ß√µes executadas em um conjunto de pods.

#### Linha a Linha do Script

#### Cabe√ßalho do Documento

```yaml
apiVersion: v1
```
- **apiVersion**: Define a vers√£o da API Kubernetes utilizada para este recurso. Aqui, `v1` √© a vers√£o para recursos b√°sicos como `Service`.

```yaml
kind: Service
```
- **kind**: Especifica o tipo de recurso Kubernetes. Neste caso, √© um `Service`.

```yaml
metadata:
  name: nginx-svc
```
- **metadata**: Cont√©m informa√ß√µes adicionais sobre o recurso.
  - **name**: Define o nome do `Service`, neste caso, `nginx-svc`.

### Especifica√ß√µes do Service

```yaml
spec:
```
- **spec**: Define a configura√ß√£o detalhada do recurso. Tudo que est√° dentro de `spec` refere-se √† implementa√ß√£o do `Service`.

```yaml
  type: ClusterIP
```
- **type**: Define como o `Service` ser√° exposto.
  - **ClusterIP**: O padr√£o. Permite o acesso ao `Service` apenas dentro do cluster.

```yaml
  selector:
    app: nginx
```
- **selector**: Define os crit√©rios para selecionar os pods associados ao `Service`.
  - **app: nginx**: Seleciona todos os pods com o r√≥tulo `app: nginx`.

```yaml
  ports:
```
- **ports**: Define as portas expostas pelo `Service`.

#### Configura√ß√£o de Portas

```yaml
  - port: 80
```
- **port**: Porta em que o `Service` estar√° escutando. Aqui, √© a porta `80`.

```yaml
    targetPort: 80
```
- **targetPort**: Porta no container para onde o tr√°fego ser√° redirecionado. Aqui, tamb√©m √© `80`.
  - Esta porta deve corresponder ao **containerPort** definido no manifesto do `Deployment` (por exemplo, `deployment.yaml`).

---

#### Resumo do Fluxo
1. **Criar o Service**:
   - O Kubernetes identifica que √© um recurso do tipo `Service`.
2. **Filtrar Pods**:
   - Usa o seletor `app: nginx` para encontrar os pods associados.
3. **Redirecionar o Tr√°fego**:
   - O tr√°fego enviado para o `Service` na porta `80` √© redirecionado para a porta `80` nos containers selecionados.




```bash
kubectl apply -f service.yaml -n first-app
```

![](image/Kubernetes/service-view.png)


para acessar vamos rodar o seguinte comando:

```bash
kubectl port-forward svc/nginx-svc -n first-app 8080:80
```

### Explica√ß√£o detalhada do comando
**Comando:**  
`kubectl port-forward svc/nginx-svc -n first-app 8080:80`

#### 1. **Contexto**  
Este comando √© usado para criar um t√∫nel local que encaminha o tr√°fego de uma porta no computador do usu√°rio para uma porta em um servi√ßo (Service) no cluster Kubernetes.

#### 2. **Componentes do comando**  

#### `kubectl`
√â a ferramenta de linha de comando usada para interagir com clusters Kubernetes.  

#### `port-forward`
√â um subcomando do `kubectl` que permite mapear uma porta do ambiente local para um pod ou servi√ßo no cluster Kubernetes.  
- Com isso, voc√™ pode acessar recursos do cluster que normalmente n√£o estariam expostos publicamente.  

#### `svc/nginx-svc`
Indica que o redirecionamento ser√° feito para um **Service** chamado `nginx-svc`.  
- O prefixo `svc/` √© usado para especificar que o alvo √© um **Service**.  

#### `-n first-app`
Especifica o namespace onde o **Service** est√° localizado.  
- Neste caso, o namespace √© `first-app`.  
- Se este argumento fosse omitido, o comando usaria o namespace padr√£o (`default`).  

#### `8080:80`
Define o mapeamento das portas:  
- `8080`: Porta local do computador onde o tr√°fego ser√° recebido.  
- `80`: Porta do servi√ßo dentro do cluster Kubernetes para a qual o tr√°fego ser√° encaminhado.  
- O tr√°fego que chega em `localhost:8080` no ambiente local ser√° redirecionado para o servi√ßo `nginx-svc` na porta `80`.

---

#### 3. **Uso pr√°tico**  
Ap√≥s executar este comando, voc√™ pode acessar o servi√ßo `nginx-svc` diretamente no navegador ou com ferramentas como `curl` via:  

http://localhost:8080

#### 4. **Cen√°rios de uso comuns**
- Testar um servi√ßo no cluster sem configur√°-lo como um recurso publicamente acess√≠vel.  
- Depura√ß√£o ou desenvolvimento local, acessando servi√ßos internos do Kubernetes de forma segura.  

---

#### 5. **Notas importantes**
- O comando precisa de acesso ao cluster Kubernetes configurado no `kubectl`.  
- Certifique-se de que a porta local (8080) n√£o esteja em uso por outro processo antes de executar o comando.  
- Se o Service estiver configurado corretamente no cluster, o tr√°fego ser√° redirecionado para os pods associados a ele.


Como vimos solucionamos o acesso interno aos pods , n√£o n√£o solucionamos o problema de acesso externo.
‚ú®

# Explorando Deployment e cen√°rios em uma aplica√ß√£o real

## ‚ú® Conteinerizando a nossa aplica√ß√£o

Vamos usar o DockerFile da Aplica√ß√£o Exemplo da Sess√£o  Docker Tutorial.

## ‚ú® Criando os Objetos do Kubernetes

Vamos Utilizar o Docker Hub para trabalhar com as imagens da nossa aplica√ß√£o

Desta forma √© necess√°rio fazer o login

```bash
docker login 
```

```yaml
# begin build
FROM node:18-alpine3.19 AS build

WORKDIR /usr/src/app

COPY package.json ./

RUN npm install

COPY . .

RUN npm run build

RUN npm ci --only=production
#end build

#begin excution
FROM node:18-alpine3.19

WORKDIR /usr/src/app

COPY --from=build /usr/src/app/package.json ./package.json
COPY --from=build /usr/src/app/dist ./dist
COPY --from=build /usr/src/app/node_modules ./node_modules

EXPOSE 3000

CMD ["npm", "run", "start:prod"]
#end excution
```

```bash
docker build -t api-rocket:v1 .
```

```bash
docker image ls api-rocket
```

```bash
docker tag api-rocket:v1 andremariadevops/api-rocket:v1 .
```

```bash
docker push andremariadevops/api-rocket:v1 
```

Agora vamos criar um objeto Deployment Kubernetes:

```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 2
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v1
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000
```


![](image/Kubernetes/file-deployment-docker-hub.png)

```bash
kubectl create namespace ns-rocket
```

![](image/Kubernetes/commands-deployment.png)


```bash
kubectl apply -f k8s -n ns-rocket
```


![](image/Kubernetes/lens-view-pod-docker-hub.png)

## ‚ú® Criando Service e explorando imagePullPolicy

Agora vamos criar um novo arquivo `service.yaml`

Ap√≥s a cria√ß√£o do arquivo vamos preencher com o seguinte script:

```yaml

apiVersion: v1
kind: Service
metadata:
  name: api-rocket-svc
spec:
  type: ClusterIP
  selector:
    api: api-rocket #  selector: matchLabels: api: api-rocket deployment.yaml
  ports:
  - port: 80
    targetPort: 3000 # - containerPort: 80 deployment.yaml


```

```bash

kubectl apply -f k8s/service.yaml -n ns-rocket

```

![](image/Kubernetes/commands-service.png)

Vamos incluir um novo end-point em nossa api :

```typescript
import { Injectable } from '@nestjs/common';

@Injectable()
export class AppService {
  getHello(): string {
    return 'Rocketset Api!';
  }

  getExample(): string {
    return 'Estou rodando no K8s!';
  }
}
```

```typescript
import { Controller, Get } from '@nestjs/common';
import { AppService } from './app.service';

@Controller()
export class AppController {
  constructor(private readonly appService: AppService) {}

  @Get()
  getHello(): string {
    return this.appService.getHello();
  }

  @Get('/example-k8s')
  getExample(): string {
    return this.appService.getExample();
  }
}
```

NO cen√°rio de CI/CD teriamos :

- 1 Commit 
- 2 Commit to build image
- 3 push
- 4 delevery

Como esse fluxo ainda n√£o est√° automatizado vamos realizar manualmente os passos.

Mas antes vamos pensar sobre version e sua import√¢ncia.

### Import√¢ncia do Versionamento de Imagens Docker

- Por que versionar imagens Docker?

Manter o versionamento de imagens Docker √© uma pr√°tica essencial para garantir a consist√™ncia, rastreabilidade e controle em ambientes de desenvolvimento, teste e produ√ß√£o. 

### Benef√≠cios do Versionamento:

1. **Consist√™ncia entre Ambientes:**
   - Usar uma tag espec√≠fica, como `v1.0.0` ou `1.2.3`, assegura que o ambiente de produ√ß√£o utilize exatamente a mesma vers√£o de imagem que foi testada em desenvolvimento e homologa√ß√£o.
   - Evita problemas relacionados a mudan√ßas inesperadas em imagens mais gen√©ricas, como `latest`.

2. **Rastreabilidade:**
   - O versionamento permite identificar rapidamente qual vers√£o da aplica√ß√£o est√° em execu√ß√£o. Isso √© fundamental para depura√ß√£o, rollback e auditorias.
   - Sem versionamento, pode ser dif√≠cil ou imposs√≠vel rastrear qual c√≥digo ou configura√ß√£o est√° sendo usado em um ambiente.

3. **Controle de Atualiza√ß√µes:**
   - Com imagens versionadas, atualiza√ß√µes podem ser planejadas e testadas cuidadosamente antes de serem aplicadas.
   - Reduz a probabilidade de interrup√ß√µes ou falhas causadas por mudan√ßas inesperadas.


### Conclus√£o

O versionamento de imagens Docker √© crucial para garantir controle e estabilidade em ambientes de desenvolvimento e produ√ß√£o. A configura√ß√£o do `"imagePullPolicy"`, por sua vez, regula como e quando as imagens devem ser atualizadas, complementando as boas pr√°ticas de versionamento e evitando problemas causados por mudan√ßas inesperadas.



Logo vamos testar o cen√°rio onde realizamos o `build` e `push` sem altera a version de v1 para v2.


```bash

docker build -t andremariadevops/api-rocket:v1 .

```


```bash

docker push andremariadevops/api-rocket:v1

```

![](image/Kubernetes/build-push-not-change-version.png)


![](image/Kubernetes/overview-image-vergion.png)

Agora ser√° que no Kubernetes vamos conseguir fazer o deployment ?

Para testar vamos tentar acessar o novo end-point http://localhost:64730/example-k8s


![](image/Kubernetes/new-end-point-not-found.png)

Nesse caso para contornar esse problema vamos usar o `"imagePullPolicy:Always "`

Para isso vamos editar o arquuivo `deployment.yaml`

```yaml

apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 2
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v1
        imagePullPolicy: Always
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000

```

### Fun√ß√£o do `"imagePullPolicy"`

O par√¢metro `"imagePullPolicy"` √© usado em ferramentas de orquestra√ß√£o, como Kubernetes, para controlar quando e como a imagem Docker deve ser baixada (ou puxada) do registro. Ele trabalha em conjunto com o versionamento para assegurar um comportamento previs√≠vel. 

### Valores Poss√≠veis do `"imagePullPolicy"`:

1. **`Always`**:
   - Faz o download da imagem toda vez que o pod √© iniciado.
   - √ötil para tags n√£o versionadas, como `latest`, garantindo que a vers√£o mais recente esteja sempre em uso.
   - Pode aumentar o tempo de inicializa√ß√£o devido ao download constante da imagem.

2. **`IfNotPresent`**:
   - Apenas baixa a imagem se ela n√£o estiver dispon√≠vel no n√≥ onde o pod est√° sendo executado.
   - Ideal para imagens versionadas, j√° que evita downloads desnecess√°rios e aproveita as imagens j√° armazenadas localmente.

3. **`Never`**:
   - Nunca tenta baixar a imagem, assumindo que ela j√° est√° dispon√≠vel localmente.
   - Geralmente usado em cen√°rios controlados, como testes locais ou ambientes restritos sem acesso ao registro.

### Como o `"imagePullPolicy"` complementa o versionamento?

- Quando se usa **versionamento**, a pol√≠tica `IfNotPresent` √© comumente utilizada para evitar downloads repetidos da mesma imagem, economizando largura de banda e acelerando o deployment.
- Para tags n√£o versionadas, como `latest`, o uso de `Always` √© recomendado para garantir que a vers√£o mais recente da imagem seja usada. No entanto, essa pr√°tica √© desencorajada em produ√ß√£o devido √† falta de previsibilidade.


```bash

kubectl apply -f k8s/deployment.yaml -n ns-rocket

```

![](image/Kubernetes/download-image-kubernetes.png)


![](image/Kubernetes/new-end-point-ok.png)

## ‚ú® Entendendo Problemas da Tag Latest

Vimos que a vers√£o √© muito importante para o health da aplica√ß√£o.

Agora vamos descobrir como fazer um rollback da aplica√ß√£o nesse cen√°rio de m√° pr√°tica de n√£o utilizar o vercionamento da imagem.


```bash
kubectl rollout history deployment/api-rocket -n ns-rocket
```


### Explica√ß√£o do comando `kubectl rollout history deployment/api-rocket`

O comando `kubectl rollout history deployment/api-rocket` √© usado para exibir o hist√≥rico de revis√µes de um *Deployment* espec√≠fico no Kubernetes. No caso do comando apresentado, ele est√° sendo aplicado ao *Deployment* chamado `api-rocket`.

### Funcionamento
- **`kubectl rollout`**: √â o comando relacionado √† administra√ß√£o de atualiza√ß√µes e mudan√ßas de recursos do tipo *Deployment* no Kubernetes.
- **`history`**: Esta subcomando exibe o hist√≥rico de revis√µes do *Deployment*, incluindo informa√ß√µes sobre altera√ß√µes realizadas em diferentes vers√µes.
- **`deployment/api-rocket`**: Especifica o recurso (neste caso, um *Deployment* chamado `api-rocket`) para o qual o hist√≥rico deve ser consultado.

### Sa√≠da Esperada
A sa√≠da do comando geralmente exibe uma tabela com as seguintes colunas:
- **REVISION**: O n√∫mero da revis√£o (come√ßando em 1 para o primeiro estado registrado).
- **CHANGE-CAUSE**: Uma descri√ß√£o sobre a causa da mudan√ßa, se fornecida no momento da aplica√ß√£o do comando `kubectl apply` ou `kubectl rollout`.



### Quando usar
- Para identificar altera√ß√µes no *Deployment* ao longo do tempo.
- Para verificar quem ou o que realizou mudan√ßas.
- Para auxiliar em *rollbacks* ou diagn√≥sticos de problemas relacionados a altera√ß√µes.


![](image/Kubernetes/result-rollout-history.png)

### Adicionando o CHANGE-CAUSE
Para que o campo `CHANGE-CAUSE` seja preenchido, √© necess√°rio especificar a causa da mudan√ßa ao aplicar altera√ß√µes, utilizando a flag `--record`, como no exemplo abaixo:

```bash
kubectl apply -f deployment.yaml --record
```


`"kubectl rollout undo"`: Reverte o Deployment para uma revis√£o anterior, √∫til quando algo deu errado ap√≥s uma atualiza√ß√£o.

```bash
kubectl rollout undo deployment/api-rocket --to-revision=1 -n ns-rocket
```

![](image/Kubernetes/rollback-version-kubernetes.png)

Agora vamos verificar e o end-point **`"/example-k8s"`** foi excluido das rotas da api.

![](image/Kubernetes/rote-error-example-k8s.png)

Como podemos ver a rota ainda existe. Mas por que?

Aqui o rollback faz o download da imagem ou reaproveita a mesma.
Como n√£o alteramos a vers√£o da imagem temos a perda o lastro, desta forma o rollback n√£o foi realizado corretamente.


## ‚ú® Criando Nova Tag e Controlando Rollback da Aplica√ß√£o

Agora que entendemos que n√£o √© uma boa pr√°tica sobre-escrever tags, vamos fazer algumas altera√ß√µes.

Nesse caso para contornar esse problema vamos usar o `"imagePullPolicy:IfNotPresent "`

Para isso vamos editar o arquuivo `deployment.yaml`

```yaml

apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 2
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v2
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000

```



```typescript
import { Injectable } from '@nestjs/common';

@Injectable()
export class AppService {
  getHello(): string {
    return 'Rocketset Api!';
  }

  getExample(): string {
    
    return `Estou rodando no K8s! ${ Date.UTC }`;
  }
}
```

```bash

docker build -t andremariadevops/api-rocket:v2 .

```


```bash

docker push andremariadevops/api-rocket:v2

```

![](image/Kubernetes/deploment-v2-api.png)


![](image/Kubernetes/docker-hub-new-version.png)

```bash

 kubectl apply -f k8s -n ns-rocket

```

![](image/Kubernetes/new-end-point-change-result.png)


```
PS C:\Repo\rocketseat.ci.api> kubectl rollout history deployment/api-rocket -n ns-rocket
deployment.apps/api-rocket 
REVISION  CHANGE-CAUSE
2         <none>
3         <none>
4         <none>

PS C:\Repo\rocketseat.ci.api> 

```

**`"!Aqui todos os comando executados no terminal foram executados de forma imperativa!"`**

## ‚ú® Trabalhando Com Estrat√©gias De Deploy

#### RollingUpdate

O **RollingUpdate** no Kubernetes √© uma estrat√©gia de atualiza√ß√£o utilizada para atualizar os pods de forma controlada e sem causar downtime no servi√ßo. Essa estrat√©gia √© usada no **Deployment** e no **StatefulSet**, permitindo substituir gradualmente os pods antigos por novos, garantindo que sempre haja um n√∫mero m√≠nimo de pods dispon√≠veis durante o processo.

#### Como funciona o RollingUpdate?

#### 1. Troca Gradual de Pods
- O Kubernetes cria novos pods com a vers√£o atualizada da aplica√ß√£o.
- Em seguida, remove os pods antigos, um por vez, ou conforme a configura√ß√£o.

#### 2. Configura√ß√µes Principais
No arquivo YAML do Deployment ou StatefulSet, voc√™ pode configurar os seguintes par√¢metros no campo `strategy`:

- **`maxUnavailable`**: Define o n√∫mero m√°ximo de pods que podem estar indispon√≠veis durante a atualiza√ß√£o.
- **`maxSurge`**: Especifica quantos pods adicionais podem ser criados al√©m do n√∫mero desejado de r√©plicas.

#### Exemplo:

```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v2
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000
```

#### 3. Interrup√ß√£o de Atualiza√ß√µes
- Se algo der errado, √© poss√≠vel interromper (pause) ou reverter a atualiza√ß√£o (rollback) para evitar downtime ou problemas maiores.

#### 4. Comandos √∫teis
- **Pausar** uma atualiza√ß√£o:
  ```bash
  kubectl rollout pause deployment/my-deployment
  ```
- **Retomar** a atualiza√ß√£o:
  ```bash
  kubectl rollout resume deployment/my-deployment
  ```
- **Verificar o status** da atualiza√ß√£o:
  ```bash
  kubectl rollout status deployment/my-deployment
  ```
- **Reverter** para uma vers√£o anterior:
  ```bash
  kubectl rollout undo deployment/my-deployment
  ```

#### 5. Vantagens do RollingUpdate
- **Sem downtime**: Garante disponibilidade durante o processo.
- **Control√°vel**: Permite configurar toler√¢ncias para indisponibilidade e escalar gradualmente.

#### 6. Limita√ß√µes
- Pode ser mais lento que uma substitui√ß√£o completa.
- N√£o √© ideal para cen√°rios em que √© necess√°ria consist√™ncia absoluta entre todos os pods (nesse caso, pode-se usar a estrat√©gia **Recreate**).

Se precisar de um exemplo mais detalhado ou ajustes para um caso espec√≠fico, me avise!


## ‚ú® Entendendo o Recreate

#### Estrat√©gia `Recreate` no Kubernetes

A estrat√©gia **`Recreate`** no Kubernetes √© uma das duas principais estrat√©gias de atualiza√ß√£o dispon√≠veis (a outra √© **`RollingUpdate`**). Essa estrat√©gia √© utilizada em controladores como o **`Deployment`** e o **`StatefulSet`**, definindo como os pods devem ser gerenciados durante uma atualiza√ß√£o.

#### O que √© a estrat√©gia `Recreate`?
- **Comportamento**: Na estrat√©gia `Recreate`, todos os pods do conjunto antigo s√£o **primeiro terminados** antes que os novos sejam criados. Isso significa que haver√° um per√≠odo de indisponibilidade enquanto a transi√ß√£o ocorre.
- **Configura√ß√£o**: Essa estrat√©gia √© √∫til para aplica√ß√µes que n√£o suportam m√∫ltiplas vers√µes em execu√ß√£o ao mesmo tempo ou quando o estado compartilhado entre as vers√µes pode causar conflitos.

#### Quando usar `Recreate`?
- **Aplica√ß√µes com estado**: Quando sua aplica√ß√£o mant√©m um estado que pode ser corrompido se m√∫ltiplas inst√¢ncias (ou vers√µes diferentes) forem executadas simultaneamente.
- **Conex√µes exclusivas**: Se o aplicativo usa conex√µes de longa dura√ß√£o, filas, ou qualquer recurso exclusivo que n√£o permita concorr√™ncia entre m√∫ltiplas vers√µes.
- **Compatibilidade restrita**: Quando n√£o h√° compatibilidade retroativa ou compatibilidade entre vers√µes (por exemplo, uma aplica√ß√£o com mudan√ßas radicais no banco de dados ou API).

#### Vantagens do `Recreate`
1. **Simplicidade**: A estrat√©gia elimina a necessidade de gerenciar m√∫ltiplas vers√µes simultaneamente.
2. **Evita conflitos**: Ideal para cen√°rios em que as vers√µes do aplicativo podem interferir uma na outra.
3. **Previsibilidade**: Como todos os pods antigos s√£o encerrados antes de iniciar os novos, √© mais f√°cil garantir consist√™ncia.

#### Desvantagens do `Recreate`
1. **Indisponibilidade**: Haver√° um per√≠odo de downtime entre o t√©rmino dos pods antigos e o in√≠cio dos novos.
2. **Impacto em usu√°rios**: Pode n√£o ser adequado para aplica√ß√µes cr√≠ticas onde a disponibilidade cont√≠nua √© essencial.

#### Dicas ao usar `Recreate`
- **Planeje janelas de manuten√ß√£o**: Use a estrat√©gia durante per√≠odos de baixa demanda para minimizar o impacto nos usu√°rios.
- **Monitore os recursos**: Certifique-se de que os novos pods podem ser inicializados rapidamente para reduzir o downtime.
- **Use readiness probes**: Isso ajuda a garantir que os novos pods estejam totalmente funcionais antes de considerar a atualiza√ß√£o como conclu√≠da.

A estrat√©gia `Recreate` √© um bom ajuste para cen√°rios espec√≠ficos, mas, para a maioria das aplica√ß√µes modernas, a **estrat√©gia `RollingUpdate`** √© mais recomendada por evitar downtime.

## ‚ú® Explorando Vari√°vel de Ambiente na Aplica√ß√£o

#### Configurar e Consumir Informa√ß√µes de um Arquivo `.env` no NestJS

No NestJS, voc√™ pode configurar e consumir informa√ß√µes de um arquivo `.env` usando o pacote `@nestjs/config`. Abaixo est√° um guia passo a passo:

---

#### 1. Instalar Depend√™ncias
Primeiro, instale o pacote necess√°rio para trabalhar com vari√°veis de ambiente:

```bash
npm install @nestjs/config dotenv
```

---

#### 2. Criar um Arquivo `.env`
Crie um arquivo `.env` na raiz do seu projeto e adicione suas vari√°veis:


```env
APP=rocketseat-app
```

#### 3. Configurar o M√≥dulo de Configura√ß√£o no AppModule
No arquivo `app.module.ts`, importe e configure o m√≥dulo de configura√ß√£o:

```typescript
import { Module } from '@nestjs/common';
import { ConfigModule } from '@nestjs/config';

@Module({
  imports: [
    ConfigModule.forRoot({
      isGlobal: true, // Torna o m√≥dulo global, n√£o precisa importar em outros m√≥dulos
      envFilePath: '.env', // Caminho do arquivo .env (opcional, padr√£o √© .env)
    }),
  ],
})
export class AppModule {}
```
#### 4. Consumir Vari√°veis no C√≥digo
Use o servi√ßo `AppService` para acessar as vari√°veis de ambiente. Voc√™ pode injetar o `ConfigService` em qualquer lugar.

```typescript
import { Injectable } from '@nestjs/common';

@Injectable()
export class AppService {
  getHello(): string {
    return 'Rocketset Api!';
  }

  getExample(): string {
    
    return `Estou rodando no K8s! ${ Date.UTC }: ${process.env.APP}`;
  }
}
```

Agora, seu aplicativo NestJS est√° configurado para consumir e validar vari√°veis de ambiente do arquivo `.env`! üöÄ

## ‚ú® Entendendo sobre o ConfigMap

```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 20%
      maxSurge: 10%
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v2
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000
```

```bash

kubectl apply -f k8s/deployment.yaml -n ns-rocket

```

```bash

docker build -t andremariadevops/api-rocket:v3 .

```


```bash

docker push andremariadevops/api-rocket:v3

```

```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 20%
      maxSurge: 10%
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v3
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000
```

```bash

kubectl apply -f k8s/deployment.yaml -n ns-rocket

```

![](image/Kubernetes/undefined-variable.png)


Como podemos ver o valor entre a APP do env e a aplica√ß√£o est√£o indefinidos. Para resolvermos esse problema vamos criar um novo arquivo 
`configmap.yaml`.


```yaml
apiVersion: v1
kind: ConfigMap

metadata:
  name: api-rocket
data:
  app-name: rocketseat-app

```


#### Prop√≥sito do Script
A defini√ß√£o de um **ConfigMap** no Kubernetes. Um **ConfigMap** √© usado para armazenar pares de chave-valor que podem ser utilizados pelas aplica√ß√µes em cont√™iners, 
permitindo a configura√ß√£o de aplica√ß√µes sem necessidade de alterar suas imagens.


#### 1. `apiVersion: v1`
- **Significado:** Define a vers√£o da API do Kubernetes que ser√° usada para criar este objeto.
- **Detalhes:** A vers√£o `v1` √© a vers√£o est√°vel e comumente usada para objetos como ConfigMaps.

#### 2. `kind: ConfigMap`
- **Significado:** Especifica o tipo de recurso que est√° sendo definido.
- **Detalhes:** Neste caso, o recurso √© um ConfigMap, que ser√° usado para armazenar dados de configura√ß√£o em forma de texto simples.

#### 3. `metadata:`
- **Significado:** Cont√©m metadados sobre o recurso.
- **Detalhes:** Esta se√ß√£o inclui informa√ß√µes como o nome do ConfigMap e, opcionalmente, labels e anota√ß√µes para identifica√ß√£o e organiza√ß√£o.

##### 3.1. `name: api-rocket`
- **Significado:** Define o nome do ConfigMap.
- **Detalhes:** O nome √© `api-rocket`, que ser√° usado para referenciar este ConfigMap em outros recursos do Kubernetes.

#### 4. `data:`
- **Significado:** Cont√©m os dados de configura√ß√£o em formato de pares de chave-valor.
- **Detalhes:** Os dados aqui definidos podem ser usados por aplica√ß√µes para configurar seu funcionamento.

##### 4.1. `app-name: rocketseat-app`
- **Significado:** Define um par chave-valor onde:
  - `app-name` √© a chave.
  - `rocketseat-app` √© o valor associado √† chave.
- **Detalhes:** Este valor pode ser utilizado por uma aplica√ß√£o em execu√ß√£o para, por exemplo, identificar o nome do aplicativo.

### Exemplo de Uso
- Este ConfigMap pode ser montado como um arquivo ou passado como vari√°vel de ambiente para os cont√™iners que fazem parte de um **Pod** no Kubernetes.



### Benef√≠cios do Uso do ConfigMap
- **Centraliza√ß√£o de Configura√ß√£o:** Facilita a altera√ß√£o de par√¢metros sem a necessidade de reconstruir as imagens dos cont√™ineres.
- **Flexibilidade:** Permite que a mesma imagem seja usada em diferentes ambientes com configura√ß√µes distintas.
- **Manuten√ß√£o:** Facilita a gest√£o de configura√ß√µes em ambientes din√¢micos e escal√°veis.



```bash

kubectl apply -f k8s/configmap.yaml -n ns-rocket

```

![](image/Kubernetes/confirm-variable-configmap.png)

```bash

kubectl apply -f k8s/deployment.yaml -n ns-rocket

```


![](image/Kubernetes/ok-variable.png)

## ‚ú® Explorando o objeto Secret


Vamos criar um novo arquivo 
`secret.yaml`.

```yaml
apiVersion: v1
kind: Secret

metadata:
  name:  api-rocket-secrets
type: Opaque
data:
  api-key: cm9ja2V0c2VhdC1hcHA=

```

`app-key: cm9ja2V0c2VhdC1hcHA=` o valor da `app-key` deve ser em base 64 


```bash

kubectl apply -f k8s/secret.yaml -n ns-rocket

```

```bash

docker build -t andremariadevops/api-rocket:v4 .

```


```bash

docker push andremariadevops/api-rocket:v4

```

```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 20%
      maxSurge: 10%
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v4
        imagePullPolicy: IfNotPresent
        env:
          - name:  APP
            valueFrom:
              configMapKeyRef:
                name:  api-rocket
                key:  app-name
          - name:  API_KEY
            valueFrom:
              secretKeyRef:
                name:  api-rocket-secrets
                key:  api-key
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000
        - containerPort: 3000
```
![](image/Kubernetes/secret-kube.png)


```bash

kubectl apply -f k8s/deployment.yaml -n ns-rocket

```

## ‚ú® Melhorando Gerenciamento de Envs

![](image/Kubernetes/change-implementation-secret-variable.png)

```yaml

apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 20%
      maxSurge: 10%
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v4
        imagePullPolicy: IfNotPresent
        envFrom:
          - configMapRef:
              name: api-rocket
          - secretRef:
              name: api-rocket-secrets
        # env:
        #   - name:  APP
        #     valueFrom:
        #       configMapKeyRef:
        #         name:  api-rocket
        #         key:  app-name
        #   - name:  API_KEY
        #     valueFrom:
        #       secretKeyRef:
        #         name:  api-rocket-secrets
        #         key:  api-key
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000

```

```yaml
apiVersion: v1
kind: ConfigMap

metadata:
  name: api-rocket

data:
  APP: rocketseat-app
  # app-name: rocketseat-app

```

```yaml
apiVersion: v1
kind: Secret

metadata:
  name:  api-rocket-secrets
type: Opaque
data:
  API_KEY: cm9ja2V0c2VhdC1hcHA=
  # api-key: cm9ja2V0c2VhdC1hcHA=

```

#### Explica√ß√£o das Mudan√ßas nos Trechos Comentados do Deployment

No **Deployment** do Kubernetes, o trecho comentado utilizava vari√°veis de ambiente espec√≠ficas referenciadas diretamente nos campos `env` (`APP` e `API_KEY`). No trecho atual, optou-se por utilizar os recursos `envFrom` para importar vari√°veis de ambiente de um **ConfigMap** e de um **Secret**. Essa altera√ß√£o traz as seguintes vantagens:

---

#### 1. Manuten√ß√£o Simplificada
- **Comentado**:
  - Vari√°veis de ambiente espec√≠ficas (`APP` e `API_KEY`) s√£o configuradas diretamente no `Deployment`. Caso outras vari√°veis precisem ser adicionadas ou modificadas, o arquivo do `Deployment` precisaria ser alterado.

- **Atual**:
  - O uso de `envFrom` permite que todas as vari√°veis contidas no `ConfigMap` e no `Secret` sejam automaticamente carregadas, evitando altera√ß√µes repetidas no `Deployment`.

---

#### 2. Segrega√ß√£o de Responsabilidades
- **Comentado**:
  - Todas as defini√ß√µes de vari√°veis (tanto sens√≠veis quanto n√£o sens√≠veis) est√£o no mesmo local.

- **Atual**:
  - Separar as vari√°veis sens√≠veis (`API_KEY`, no `Secret`) e n√£o sens√≠veis (`APP`, no `ConfigMap`) melhora a organiza√ß√£o e facilita o controle. **ConfigMaps** s√£o usados para dados n√£o confidenciais, enquanto **Secrets** s√£o criptografados.

---

#### 3. Escalabilidade e Reutiliza√ß√£o
- **Comentado**:
  - Cada vari√°vel de ambiente precisava ser explicitamente mapeada, tornando o arquivo de configura√ß√£o menos reutiliz√°vel em diferentes cen√°rios.

- **Atual**:
  - `ConfigMap` e `Secret` podem ser reutilizados por outros **Deployments** ou servi√ßos que precisem das mesmas vari√°veis. Isso elimina redund√¢ncias e simplifica a gest√£o de configura√ß√µes.

---

#### 4. Redu√ß√£o de Erros
- **Comentado**:
  - O uso de `configMapKeyRef` e `secretKeyRef` exige especificar cada chave e pode levar a erros caso o nome ou a chave estejam incorretos.

- **Atual**:
  - `envFrom` reduz a possibilidade de erros, pois todas as chaves v√°lidas no `ConfigMap` ou no `Secret` s√£o automaticamente carregadas.

---

#### Altera√ß√µes no **ConfigMap** e **Secret**

##### **ConfigMap**
- **Comentado**:
  - Defini√ß√£o direta da chave `app-name`, que √© referenciada no `Deployment`.
- **Atual**:
  - Alterado para usar diretamente a vari√°vel `APP`, facilitando o carregamento pelo `envFrom` e mantendo consist√™ncia com o `.env`.

##### **Secret**
- **Comentado**:
  - Chave nomeada como `api-key`, usada diretamente no `Deployment`.
- **Atual**:
  - Alterada para `API_KEY`, mantendo consist√™ncia com o `.env` e simplificando o carregamento via `envFrom`.

---

#### Vantagens Adicionais
1. **Conformidade com Boas Pr√°ticas**: A separa√ß√£o entre ConfigMap e Secret √© alinhada √†s pr√°ticas recomendadas do Kubernetes.
2. **Integra√ß√£o com Ferramentas DevOps**: O uso de `.env` como refer√™ncia facilita a integra√ß√£o com pipelines de CI/CD e evita discrep√¢ncias entre o ambiente local e o Kubernetes.
3. **Escalabilidade**: O novo formato suporta com facilidade a adi√ß√£o de mais vari√°veis, sem necessidade de altera√ß√µes estruturais no `Deployment`.



```bash

kubectl apply -f k8s/secret.yaml -n ns-rocket

```

```bash

kubectl apply -f k8s/configmap.yaml -n ns-rocket

```

```bash

kubectl apply -f k8s/deployment.yaml -n ns-rocket

```


# Conhecendo o HPA

## O que √© Escala

## Conhecendo a escala vertical

**`"Escala Vertical"`** 
- Aumenta o tamanho da m√°quina - em termos de cpu, mem√≥ria, armazenamento.
- Necess√°rio em casos de grande escala com apenas uma m√°quina.
- Menor redund√¢ncia e maior risco de indisponibilidade.
- Limite do pr√≥prio hardware
- Promove down time dentro de um determinado per√≠odo
- VPA dentro do k8s

## Explorando a escala horizontal

**`"Escala horizontal"`** 
- Replica√ß√£o da infraestrutura.
- Visa Distribuir igualmente as cargas de trabalho.
- Aumento a toler√¢ncia a falhas.
- Por ser horizontal, temos uma maior redund√¢ncia.
- A escala n√£o est√° restrita aos limites do hardware.
- Condicionada aos recursos e/ou eventos - KEDA.
- ! Poss√≠veis problemas na consist√™ncia de dados!

## Como o Metrics-Server funciona

O **`"Metrics"`** Server √© um componente essencial no ecossistema do Kubernetes para coletar e expor m√©tricas de uso de recursos `(como CPU e mem√≥ria)` em tempo real dos n√≥s e dos pods em um cluster. 

Ele √© um substituto moderno para o antigo heapster e faz parte das APIs de m√©tricas do Kubernetes.

---

#### **Como funciona o Metrics Server**

1. **Coleta de M√©tricas:**
   - O Metrics Server coleta m√©tricas de uso de recursos diretamente dos agentes do Kubernetes, chamados de **kubelet**, que est√£o presentes em cada n√≥ do cluster.
   - O kubelet usa o **cAdvisor** (integrado) para monitorar o uso de recursos no n√≠vel do n√≥ e dos cont√™ineres.

2. **Exposi√ß√£o de M√©tricas:**
   - As m√©tricas coletadas pelo Metrics Server s√£o expostas por meio da **API de m√©tricas do Kubernetes** (`metrics.k8s.io`).
   - Essas m√©tricas s√£o disponibilizadas para componentes internos, como o **Horizontal Pod Autoscaler (HPA)**, e tamb√©m podem ser acessadas por comandos como `kubectl top`.

3. **Efici√™ncia e Escalabilidade:**
   - Ele √© projetado para ser leve e eficiente, armazenando apenas m√©tricas em tempo real (n√£o mant√©m hist√≥rico).
   - √â ideal para aplica√ß√µes onde o foco est√° em a√ß√µes imediatas baseadas em m√©tricas, como escalonamento horizontal.

---

#### **Para que serve o Metrics Server**

1. **Escalonamento Horizontal Autom√°tico (HPA):**
   - Permite que o Kubernetes ajuste automaticamente o n√∫mero de r√©plicas de um deployment ou replica set com base em m√©tricas de uso de CPU e mem√≥ria.

2. **Monitoramento em Tempo Real:**
   - Fornece informa√ß√µes sobre o consumo atual de recursos dos pods e n√≥s do cluster.

## Adicionando o Metrics-Server no nosso Cluster"

Vamos acessar ao site :

https://github.com/kubernetes-sigs/metrics-server

Vamos rodar o seguinte comando :

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

![](image/Kubernetes/metrics-server-command.png)

Vamos ver se funciona.

```bash
kubectl get po -n kube-system
```

![](image/Kubernetes/command-kubctl-get-po-metrics-server.png)

Como podemos ver na imagem o pod `metrics-server-54bf7cdd6-z7bvj` n√£o esta em execu√ß√£o.

Para analizarmos melhor o problema vamos rodar o seguinte comando:

```bash
kubectl logs metrics-server-54bf7cdd6-z7bvj -n kube-system
```

```bash
E1203 22:07:33.612329       1 scraper.go:149] "Failed to scrape node" err="Get \"https://172.23.0.2:10250/metrics/resource\": tls: failed to verify certificate: x509: cannot validate certificate for 172.23.0.2 because it doesn't contain any IP SANs" node="secund-cluster-rocketseat-worker"
E1203 2
```

Como estamos em um ambiente local n√£o √© poss√≠vel validar o certificado.

Para resolver esse problema vamos ao site https://github.com/kubernetes-sigs/metrics-server 

![](image/Kubernetes/solve-problema-certification.png)

- primeiro √© excluir o metrics-server

```bash
kubectl delete -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

- Vamos acessar a pasta k8s e vamos rodar o seguinte comando:

```bash
wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

ou 

```bash
Invoke-WebRequest -Uri https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml -OutFile components.yaml

```

Aqui fizemos o download para a pasta para internalizar o arquivo para que possamos configura-lo conforme a necessidade.

![](image/Kubernetes/new-file.yaml)

Agora vamos editar o conteudo do arquivo.

- renomear o arquivo para `metrics-server.yaml`
- vamos adicionar `--kubelet-insecure-tls` no trecho `- args` do trecho `Deployment` do arquivo.

![](image/Kubernetes/add-kubelet-insecure-tls.png)

- vamos rodar o camando

```bash
kubectl apply -f metrics-server.yaml
```

```bash
kubectl get po -n kube-system
```

![](image/Kubernetes/log-ok-metrics-server.png)

agora podemos ver que as metricas nos pods relacionados a nossa api possuem valores:

![](image/Kubernetes/pods-metricris-log.png)

- Consultando logs pleo comando:

```bash
kubectl top po -n ns-rocket
```

![](image/Kubernetes/logs-top-pods.png)

## Entendendo os Principais Triggers

## Explorando a V1 do HPA

Vamos criar uma novo arquivo `hpa.yaml`

```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler

metadata:
  name: api-rocket-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-rocket
  minReplicas: 3
  maxReplicas: 8
  targetCPUUtilizationPercentage: 75

```

![](image/Kubernetes/new-config-file-hpa.png)


```bash
kubectl apply -f k8s/hpa.yaml -n ns-rocket
```

```bash
kubectl get hpa -n ns-rocket
```

![](image/Kubernetes/overview-hpa-start.png)

Aqui estamos usando a v1 para o hpa vamos. Vamos fazer o upgrade para V2. Mas antes vamos excluir o hpa do cluster.

```bash
kubectl delete -f k8s/hpa.yaml -n ns-rocket
```
Vamos renomear o arquivo para `hpa-v1.yaml`

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler

metadata:
  name: api-rocket-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-rocket
  minReplicas: 3
  maxReplicas: 8
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  
```

```bash
kubectl apply -f k8s/hpa.yaml -n ns-rocket
```

```bash
kubectl get hpa -n ns-rocket
```

```bash
PS C:\Repo\rocketseat.ci.api> kubectl get hpa -n ns-rocket
NAME             REFERENCE               TARGETS                        MINPODS   MAXPODS   REPLICAS   AGE
api-rocket-hpa   Deployment/api-rocket   cpu: 0%/75%, memory: 79%/80%   3         8         3          36s
PS C:\Repo\rocketseat.ci.api> 

```

## Criando o HPA Utilizando a V2

Vamos criar uma novo arquivo `hpa.yaml`

```yaml

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler

metadata:
  name: api-rocket-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-rocket
  minReplicas: 3
  maxReplicas: 8
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  

```

```bash
kubectl apply -f k8s/hpa-v2.yaml -n ns-rocket
```

```bash
kubectl get hpa -n ns-rocket
```

## Estressando a Nossa Aplica√ß√£o


Vamos testar a ideia de `HorizontalPodAutoscaler` estressando a aplica√ß√£o.

Para isso vamos acessar o site : https://github.com/fortio/fortio

Aqui temos a possibilidade de realizar testes de carga.

```bash
kubectl run -it fortio -n ns-rocket --rm --image=fortio/fortio -- load -qps 6000 -t 120s -c 50 "http://api-rocket-svc/example-k8s"
```
#### Descri√ß√£o do Comando

Este comando executa um **teste de carga** em um servi√ßo web hospedado no Kubernetes usando a ferramenta **Fortio**. Abaixo est√° o detalhamento de cada parte do comando.

---

#### Partes do Comando

#### 1. `kubectl run`
- **`kubectl`**: Ferramenta CLI para interagir com clusters Kubernetes.
- **`run`**: Cria e executa um pod no cluster Kubernetes.

#### 2. Nome do pod: `fortio`
- Define o nome do pod tempor√°rio como **`fortio`**.

#### 3. `-it`
- **`-i`**: Habilita entrada interativa para o pod.
- **`-t`**: Ativa o modo de terminal, conectando seu terminal local ao processo do pod.

#### 4. `-n ns-rocket`
- Especifica o **namespace** Kubernetes onde o pod ser√° criado.
- **`ns-rocket`**: Nome do namespace.

#### 5. `--rm`
- Remove automaticamente o pod ap√≥s sua execu√ß√£o. Isso evita acumular pods tempor√°rios.

#### 6. `--image=fortio/fortio`
- Define a **imagem Docker** a ser usada.
- **`fortio/fortio`**: Imagem da ferramenta Fortio, usada para testes de desempenho e carga.

#### 7. `-- load`
- Ativa o modo **teste de carga** no Fortio.

#### 8. `-qps 6000`
- Define o n√∫mero de **requisi√ß√µes por segundo (QPS)**.
- **`6000`**: Envia **6.000 requisi√ß√µes por segundo**.

#### 9. `-t 120s`
- Especifica a **dura√ß√£o do teste**.
- **`120s`**: O teste ser√° executado por **120 segundos (2 minutos)**.

#### 10. `-c 50`
- Define o n√∫mero de **conex√µes simult√¢neas (threads)**.
- **`50`**: Usa **50 conex√µes simult√¢neas** durante o teste.

#### 11. `"http://api-rocket-svc/example-k8s"`
- Define o **endpoint** a ser testado.
- **`http://api-rocket-svc/example-k8s`**: URL do servi√ßo que ser√° submetido ao teste de carga.
- Como est√° dentro do Cluster √© poss√≠vel enxergar o servi√ßo.
---

#### Resumo do que o comando faz

1. Cria um pod tempor√°rio no namespace **`ns-rocket`** utilizando a imagem do Fortio.
2. Executa um teste de carga contra o endpoint **`http://api-rocket-svc/example-k8s`**.
3. Envia **6.000 requisi√ß√µes por segundo** durante **120 segundos**, utilizando **50 conex√µes simult√¢neas**.
4. Ap√≥s o t√©rmino do teste, o pod √© automaticamente removido.

---

#### Resultados Esperados

Durante o teste, o Fortio coleta as seguintes m√©tricas:
- **Lat√™ncia das requisi√ß√µes** (ex.: p95, p99).
- **Taxa de sucesso** das requisi√ß√µes.
- **Erros de rede** ou falhas no servi√ßo.


```bash

Connection time histogram (s) : count 50 avg 0.00077979046 +/- 0.002684 min 4.5061e-05 max 0.015008246 sum 0.038989523
# range, mid point, percentile, count
>= 4.5061e-05 <= 0.001 , 0.000522531 , 94.00, 47
> 0.004 <= 0.005 , 0.0045 , 96.00, 1
> 0.011 <= 0.012 , 0.0115 , 98.00, 1
> 0.014 <= 0.0150082 , 0.0145041 , 100.00, 1
# target 50% 0.00054329
# target 75% 0.000802784
# target 90% 0.000958481
# target 99% 0.0145041
# target 99.9% 0.0149578
Sockets used: 50 (for perfect keepalive, would be 50)
Uniform: false, Jitter: false, Catchup allowed: true
IP addresses distribution:
10.96.107.209:80: 50
Code 200 : 165015 (100.0 %)
Response Header Sizes : count 165015 avg 228 +/- 0 min 228 max 228 sum 37623420
Response Body/Total Sizes : count 165015 avg 298 +/- 0 min 298 max 298 sum 49174470
All done 165015 calls (plus 50 warmup) 36.354 ms avg, 1374.1 qps
Session ended, resume using 'kubectl attach fortio -c fortio -i -t' command when the pod is running
pod "fortio" deleted

```

## Explorando mais cen√°rios de estresse

Vamos alterar o arquivo `app.service.ts` da aplica√ß√£o :

```typescript
import { Injectable } from '@nestjs/common';
import  { createWriteStream } from 'fs'
@Injectable()
export class AppService {
  getHello(): string {
    console.log(`secret: ${ process.env.API_KEY }`)
    return 'Rocketset Api!';
  }

  getExample(): string {
    const file = createWriteStream('rocketseat.txt')
    for (let index = 0; index <= 10000; index++) {
      file.write('Estou escrevendo em um arquivo\n');
    }
    file.end();
    return `Estou rodando no K8s! ${ Date.UTC }: ${process.env.APP}`;
  }
}
```

```bash
docker build -t andremariadevops/api-rocket:v5 .    
```

```bash

docker push andremariadevops/api-rocket:v5  

```

```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 20%
      maxSurge: 10%
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v5
        imagePullPolicy: IfNotPresent
        envFrom:
          - configMapRef:
              name: api-rocket
          - secretRef:
              name: api-rocket-secrets
        # env:
        #   - name:  APP
        #     valueFrom:
        #       configMapKeyRef:
        #         name:  api-rocket
        #         key:  app-name
        #   - name:  API_KEY
        #     valueFrom:
        #       secretKeyRef:
        #         name:  api-rocket-secrets
        #         key:  api-key
        resources:
          requests:
            cpu: 100m
            memory: 64Mi
          limits:
            cpu: "200m"
            memory: "128Mi"
        ports:
        - containerPort: 3000
```

```bash
 kubectl apply -f k8s/deployment.yaml -n ns-rocket 
```

Agora vamos iniciar o nosso teste de estesse

```bash
kubectl run -it fortio -n ns-rocket --rm --image=fortio/fortio -- load -qps 6000 -t 120s -c 50 "http://api-rocket-svc/example-k8s"
```

```bash
Connection time histogram (s) : count 252 avg 0.00070557625 +/- 0.003099 min 4.8129e-05 max 0.03114827 sum 0.177805214
# range, mid point, percentile, count
>= 4.8129e-05 <= 0.001 , 0.000524065 , 95.63, 241
> 0.001 <= 0.002 , 0.0015 , 96.83, 3
> 0.002 <= 0.003 , 0.0025 , 97.62, 2
> 0.003 <= 0.004 , 0.0035 , 98.02, 1
> 0.004 <= 0.005 , 0.0045 , 98.41, 1
> 0.006 <= 0.007 , 0.0065 , 98.81, 1
> 0.025 <= 0.03 , 0.0275 , 99.60, 2
> 0.03 <= 0.0311483 , 0.0305741 , 100.00, 1
# target 50% 0.000543895
# target 75% 0.000793761
# target 90% 0.000943681
# target 99% 0.0262
# target 99.9% 0.0308589
Sockets used: 252 (for perfect keepalive, would be 50)
Uniform: false, Jitter: false, Catchup allowed: true
IP addresses distribution:
10.96.107.209:80: 252
Code  -1 : 120 (2.8 %)
Code 200 : 4159 (97.2 %)
Response Header Sizes : count 4279 avg 221.60598 +/- 37.64 min 0 max 228 sum 948252
Response Body/Total Sizes : count 4279 avg 289.64291 +/- 49.2 min 0 max 298 sum 1239382
All done 4279 calls (plus 50 warmup) 1413.665 ms avg, 34.9 qps
Session ended, resume using 'kubectl attach fortio -c fortio -i -t' command when the pod is running
pod "fortio" deleted
```

## Alterando Recursos e R√©plicas da Aplica√ß√£o

NO ultimo test temos como resultado ***`"All done 4279 calls (plus 50 warmup) 1413.665 ms avg, 34.9 qps"`***

vamos altera o arquivo `hpa-v2.yaml` 

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler

metadata:
  name: api-rocket-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-rocket
  minReplicas: 6
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  
```

vamos altera o arquivo `deployment.yaml` 

```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: api-rocket

spec:
  replicas: 6
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 20%
      maxSurge: 10%
  selector:
    matchLabels:
      api: api-rocket
  template:
    metadata:
      labels:
        api: api-rocket
    spec:
      containers:
      - name: api-rocket
        image: andremariadevops/api-rocket:v5
        imagePullPolicy: IfNotPresent
        envFrom:
          - configMapRef:
              name: api-rocket
          - secretRef:
              name: api-rocket-secrets
        # env:
        #   - name:  APP
        #     valueFrom:
        #       configMapKeyRef:
        #         name:  api-rocket
        #         key:  app-name
        #   - name:  API_KEY
        #     valueFrom:
        #       secretKeyRef:
        #         name:  api-rocket-secrets
        #         key:  api-key
        resources:
          requests:
            cpu: 400m
            memory: 64Mi
          limits:
            cpu: "700m"
            memory: "128Mi"
        ports:
        - containerPort: 3000
```

```bash
kubectl run -it fortio -n ns-rocket --rm --image=fortio/fortio -- load -qps 6000 -t 120s -c 50 "http://api-rocket-svc/example-k8s"
```

```bash

Connection time histogram (s) : count 51 avg 0.024701479 +/- 0.03977 min 8.0373e-05 max 0.100979221 sum 1.25977541
# range, mid point, percentile, count
>= 8.0373e-05 <= 0.001 , 0.000540186 , 52.94, 27
> 0.001 <= 0.002 , 0.0015 , 56.86, 2
> 0.004 <= 0.005 , 0.0045 , 58.82, 1
> 0.005 <= 0.006 , 0.0055 , 66.67, 4
> 0.006 <= 0.007 , 0.0065 , 70.59, 2
> 0.016 <= 0.018 , 0.017 , 72.55, 1
> 0.03 <= 0.035 , 0.0325 , 74.51, 1
> 0.035 <= 0.04 , 0.0375 , 76.47, 1
> 0.04 <= 0.045 , 0.0425 , 78.43, 1
> 0.08 <= 0.09 , 0.085 , 80.39, 1
> 0.09 <= 0.1 , 0.095 , 84.31, 2
> 0.1 <= 0.100979 , 0.10049 , 100.00, 8
# target 50% 0.000946945
# target 75% 0.03625
# target 90% 0.100355
# target 99% 0.100917
# target 99.9% 0.100973
Sockets used: 51 (for perfect keepalive, would be 50)
Uniform: false, Jitter: false, Catchup allowed: true
IP addresses distribution:
10.96.107.209:80: 51
Code 200 : 10003 (100.0 %)
Response Header Sizes : count 10003 avg 228 +/- 0 min 228 max 228 sum 2280684
Response Body/Total Sizes : count 10003 avg 298 +/- 0 min 298 max 298 sum 2980894
All done 10003 calls (plus 50 warmup) 600.651 ms avg, 82.9 qps
Session ended, resume using 'kubectl attach fortio -c fortio -i -t' command when the pod is running
pod "fortio" deleted
```

***`"All done 4279 calls (plus 50 warmup) 1413.665 ms avg, 34.9 qps"`***
***`"All done 10003 calls (plus 50 warmup) 600.651 ms avg, 82.9 qps"`***

Como podemos ver, o teste foi executado em um desempenho superior.

## Definindo tempo de rea√ß√£o para escalonar a quantidade de r√©plicas

Vamos alterar o arquivo `hpa-v2.yaml`

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler

metadata:
  name: api-rocket-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-rocket
  minReplicas: 6
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
        stabilizationWindowSeconds: 30
        policies:
          - type: Pods
            value: 2
            periodSeconds: 15
        #   - type: Percent
        #     value: 20
        #     periodSeconds: 15
        # selectPolicy : Max
```


#### Comportamento do HorizontalPodAutoscaler (HPA)

O trecho `behavior` define o comportamento personalizado de escalonamento do **HorizontalPodAutoscaler (HPA)** ao aumentar ou diminuir o n√∫mero de r√©plicas dos pods em um cluster Kubernetes. Vamos analisar cada parte desse trecho:

---

#### Se√ß√£o: behavior

Essa se√ß√£o √© opcional e permite configurar pol√≠ticas espec√≠ficas para **escalonamento para cima** (`scaleUp`) ou **escalonamento para baixo** (`scaleDown`), fornecendo maior controle sobre como e quando o HPA deve realizar essas a√ß√µes.

---

#### scaleDown (Escalonamento para baixo)

Aqui, configura-se como o HPA reduzir√° o n√∫mero de r√©plicas dos pods.

#### stabilizationWindowSeconds: 30

- Especifica uma "janela de estabiliza√ß√£o" de **30 segundos**.
- Isso significa que o HPA esperar√° **30 segundos** antes de decidir reduzir o n√∫mero de r√©plicas ap√≥s detectar que o uso de recursos est√° abaixo do alvo.
- Serve para evitar que o HPA oscile frequentemente entre diferentes n√∫meros de r√©plicas em situa√ß√µes de carga vari√°vel (chamado de *flapping*).

---

#### policies

Define as pol√≠ticas para limitar como o **escalonamento para baixo** pode ocorrer. Neste exemplo, h√° apenas uma pol√≠tica ativa:

- **type: Pods**
  - Essa pol√≠tica controla diretamente o n√∫mero de r√©plicas que podem ser reduzidas em uma √∫nica a√ß√£o.
  - **value: 2**: Especifica que, no m√°ximo, o HPA pode reduzir **2 r√©plicas** de uma s√≥ vez.
  - **periodSeconds: 15**: Especifica que essa redu√ß√£o m√°xima (**2 r√©plicas**) pode ocorrer a cada **15 segundos**.

---

#### Coment√°rio

As linhas comentadas indicam que o HPA poderia usar outra pol√≠tica (baseada em **porcentagem**), mas ela foi desativada. Se a pol√≠tica `Percent` fosse ativada:

- **type: Percent**: O HPA reduziria as r√©plicas com base em uma porcentagem do n√∫mero total de pods em execu√ß√£o.
- **value: 20**: Reduziria no m√°ximo **20%** dos pods em execu√ß√£o.

#### selectPolicy

Define qual pol√≠tica usar se houver v√°rias aplic√°veis. Por exemplo:

- **Max**: Escolhe a pol√≠tica que resulta na maior redu√ß√£o (mais agressiva).
- **Min**: Escolhe a pol√≠tica que resulta na menor redu√ß√£o (mais conservadora).

‚ö†Ô∏è Apenas uma pol√≠tica pode ser aplicada por vez, e o `selectPolicy` especifica qual deve ser priorizada se houver m√∫ltiplas pol√≠ticas ativas.


#### Explica√ß√£o do Trecho `behavior` para `scaleUp` no HorizontalPodAutoscaler (HPA)

O trecho `behavior` configura o comportamento do **HorizontalPodAutoscaler (HPA)** para escalonamento **para cima** (`scaleUp`), ou seja, aumentar o n√∫mero de r√©plicas dos pods quando h√° aumento na carga. Abaixo est√° uma explica√ß√£o detalhada:

#### Trecho `scaleUp`

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler

metadata:
  name: api-rocket-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-rocket
  minReplicas: 6
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
        stabilizationWindowSeconds: 30
        policies:
          - type: Pods
            value: 2
            periodSeconds: 15
        #   - type: Percent
        #     value: 20
        #     periodSeconds: 15
        # selectPolicy : Max
    scaleUp:
        stabilizationWindowSeconds: 5
        policies:
          - type: Pods
            value: 2
            periodSeconds: 5
```
#### Se√ß√£o: `scaleUp`

Essa se√ß√£o define como o HPA ir√° aumentar o n√∫mero de r√©plicas do Deployment.

#### `stabilizationWindowSeconds: 5`
- Especifica uma janela de estabiliza√ß√£o de **5 segundos**.
- Isso significa que o HPA esperar√° **5 segundos** antes de aumentar o n√∫mero de r√©plicas, mesmo que as m√©tricas indiquem a necessidade de escalonamento.
- Esse intervalo reduz oscila√ß√µes r√°pidas no n√∫mero de r√©plicas, garantindo que o aumento seja consistente.

#### `policies`
Define as pol√≠ticas que limitam como o escalonamento para cima ocorrer√°. Aqui, h√° apenas uma pol√≠tica ativa:

- **`type: Pods`**
  - Define que o aumento ser√° baseado no n√∫mero absoluto de r√©plicas.
  - **`value: 2`**: O HPA pode aumentar no m√°ximo **2 r√©plicas** por vez.
  - **`periodSeconds: 5`**: Esse aumento de 2 r√©plicas pode ocorrer no m√°ximo a cada **5 segundos**.

---

#### Como Funciona o Escalonamento para Cima

Quando o HPA detecta que a carga em um Deployment ultrapassou os limites definidos nas m√©tricas (como uso de CPU ou mem√≥ria), ele inicia o processo de escalonamento para cima. O comportamento √© configurado da seguinte maneira:

#### Janela de Estabiliza√ß√£o (`stabilizationWindowSeconds`)
- Serve para prevenir oscila√ß√µes r√°pidas no n√∫mero de r√©plicas causadas por varia√ß√µes moment√¢neas na carga.

#### Pol√≠tica Baseada em R√©plicas Absolutas (`type: Pods`)
- Permite um aumento controlado no n√∫mero de r√©plicas.
- Por exemplo, se h√° **4 r√©plicas** atualmente e a carga exige mais r√©plicas, o HPA s√≥ adicionar√° **at√© 2 r√©plicas** em intervalos de **5 segundos**, mesmo que mais r√©plicas sejam necess√°rias.

---

#### Vantagens do Trecho Configurado

#### **Controle Fino do Escalonamento**
- Evita um aumento excessivo e r√°pido no n√∫mero de r√©plicas, o que pode levar ao uso ineficiente de recursos.
- Permite um ajuste gradual e controlado.

#### **Estabilidade**
- Reduz oscila√ß√µes no n√∫mero de r√©plicas, mesmo em cen√°rios de carga vari√°vel.

#### **Respostas R√°pidas**
- A janela de estabiliza√ß√£o curta (**5 segundos**) permite respostas quase imediatas em situa√ß√µes de alta demanda.


Agora vamos testar a altera√ß√£o rodando o comando 

```bash
kubectl apply -f k8s/hpa-v2.yaml -n ns-rocket
```


Agora podemos dora novamente o teste de estresse:

```bash
kubectl run -it fortio -n ns-rocket --rm --image=fortio/fortio -- load -qps 6000 -t 120s -c 50 "http://api-rocket-svc/example-k8s"
```

```bash
Connection time histogram (s) : count 57 avg 0.0013138895 +/- 0.00426 min 7.8184e-05 max 0.02913538 sum 0.074891704
# range, mid point, percentile, count
>= 7.8184e-05 <= 0.001 , 0.000539092 , 85.96, 49
> 0.001 <= 0.002 , 0.0015 , 92.98, 4
> 0.003 <= 0.004 , 0.0035 , 94.74, 1
> 0.004 <= 0.005 , 0.0045 , 96.49, 1
> 0.014 <= 0.016 , 0.015 , 98.25, 1
> 0.025 <= 0.0291354 , 0.0270677 , 100.00, 1
# target 50% 0.000606308
# target 75% 0.000879972
# target 90% 0.001575
# target 99% 0.0267782
# target 99.9% 0.0288997
Sockets used: 57 (for perfect keepalive, would be 50)
Uniform: false, Jitter: false, Catchup allowed: true
IP addresses distribution:
10.96.107.209:80: 57
Code 200 : 10411 (100.0 %)
Response Header Sizes : count 10411 avg 228 +/- 0 min 228 max 228 sum 2373708
Response Body/Total Sizes : count 10411 avg 298 +/- 0 min 298 max 298 sum 3102478
All done 10411 calls (plus 50 warmup) 579.522 ms avg, 85.7 qps
Session ended, resume using 'kubectl attach fortio -c fortio -i -t' command when the pod is running
pod "fortio" deleted
```

Comparando o resultado com as outras execu√ß√µes de teste de estresse temos:

***`"All done 4279 calls (plus 50 warmup) 1413.665 ms avg, 34.9 qps"`***
***`"All done 10003 calls (plus 50 warmup) 600.651 ms avg, 82.9 qps"`***

***`"All done 10411 calls (plus 50 warmup) 579.522 ms avg, 85.7 qps"`***